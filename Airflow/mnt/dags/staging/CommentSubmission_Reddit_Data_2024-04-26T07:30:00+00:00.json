[{"comment_ID": "l1bnj0x", "comment_Body": "I think some one played with the numbers, i re-checked the values and here you go : [https://ibb.co/vvYSKc1](https://ibb.co/vvYSKc1)\n\nthe Interest for data engineer is the same for the moment.", "comment_Score": 1, "comment_Author": "Acceptable-Sail-4575", "comment_Link_id": "1ccsf39", "Create Date": "2024-04-26 08:26:46+00:00"}, {"comment_ID": "l1bmwbp", "comment_Body": "That's a pathetic argument - I should be skeptical of everything you put? Just don't put skeptical stuff up", "comment_Score": 1, "comment_Author": "Ok_Raspberry5383", "comment_Link_id": "1ccodiy", "Create Date": "2024-04-26 08:18:52+00:00"}, {"comment_ID": "l1bmp5i", "comment_Body": "Fullstack data (engineering) ??\n\nHonestly I hear a lot of DEs (me included when I was in such roles) complain about being too far removed from the actual tangible value delivered: those shiny dashboards.\nThe only way I've had the chance of getting closer to this value was working for very small teams where I could own the problem from start to end.\n\nHence \"fullstack data\" is the only way I see to reconcile doing both technical work (setting the foundations) and seeing the actual value that provides in the end...\n\nAnd what I find is actually that there's often more value in delivering individual insights to the tools that the business teams use, rather than the shiny dashboards a lot of people have associated data teams with ..", "comment_Score": 1, "comment_Author": "briceluu", "comment_Link_id": "1ccsf39", "Create Date": "2024-04-26 08:16:23+00:00"}, {"comment_ID": "l1bljlk", "comment_Body": "I second this. For this size of data is really the quickest thing to setup.", "comment_Score": 1, "comment_Author": "wtfzambo", "comment_Link_id": "1cd0tmv", "Create Date": "2024-04-26 08:01:56+00:00"}, {"comment_ID": "l1blb49", "comment_Body": "Yes wsl2 + vscode + powertoys.\nBest combo", "comment_Score": 1, "comment_Author": "rodeslab", "comment_Link_id": "1cdc878", "Create Date": "2024-04-26 07:59:01+00:00"}, {"comment_ID": "l1bl8jz", "comment_Body": "The founder is a nice dude but I'm not a fan of the product itself, despite it being branded exactly to attract people like me.\n\nNotebook interfaces give me the ick.\n\nThis said, I'm gonna offer a different perspective.\n\nI feel like in our community, having an orchestrator in one's own pipeline is a must, kind of like having running water in a house.\n\nBut to be honest, I'm starting to think that this is a dogma parroted through the years, and that in a lot of cases, orchestrators don't fit at all and are actually overkill.\n\nIn most system I worked with, just once I thought an orchestrator was necessary.\n\nObviously, this is my subjective experience, but let me ask you: what do you think you need an orchestrator for?", "comment_Score": 2, "comment_Author": "wtfzambo", "comment_Link_id": "1cda190", "Create Date": "2024-04-26 07:58:09+00:00"}, {"comment_ID": "l1bkh2p", "comment_Body": "at my saas company we have (10) DEs on the customer side (data extraction and integration, etl) and (1) DE on the platform side. customer side has weekly rotating on call during the pipeline hours (8am-8pm). and during weekends", "comment_Score": 1, "comment_Author": "ImportantAward4608", "comment_Link_id": "1cd6v3c", "Create Date": "2024-04-26 07:48:46+00:00"}, {"comment_ID": "l1bk96n", "comment_Body": "I recently moved to Windows with WSL2, it's going well so far. The WSL plugin for vscode is perfect for me, as it's just like using vscode in Linux.\n\nMake sure to only use programs installed in WSL while you're inside WSL though. I had the gcloud CLI installed on Windows and it would take a very long time to run any gcloud command as the interop performance on WSL2 is not optimal. Once I uninstalled the gcloud CLI on Windows and reinstalled on WSL it was much faster", "comment_Score": 2, "comment_Author": "hennyblub", "comment_Link_id": "1cdc878", "Create Date": "2024-04-26 07:46:04+00:00"}, {"comment_ID": "l1bjxj7", "comment_Body": "Are you interested in transitioning into Data Engineering? Read our community guide: https://dataengineering.wiki/FAQ/How+can+I+transition+into+Data+Engineering\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dataengineering) if you have any questions or concerns.*", "comment_Score": 1, "comment_Author": "AutoModerator", "comment_Link_id": "1cdfiow", "Create Date": "2024-04-26 07:42:03+00:00"}, {"comment_ID": "l1bjxip", "comment_Body": "You can find a list of community-submitted learning resources here: https://dataengineering.wiki/Learning+Resources\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dataengineering) if you have any questions or concerns.*", "comment_Score": 1, "comment_Author": "AutoModerator", "comment_Link_id": "1cdfiow", "Create Date": "2024-04-26 07:42:03+00:00"}, {"comment_ID": "l1bjlhs", "comment_Body": "Pretty much this.\n\nUnless you are distrohopper.", "comment_Score": 1, "comment_Author": "n3pst3r_007", "comment_Link_id": "1cdc878", "Create Date": "2024-04-26 07:37:57+00:00"}, {"comment_ID": "l1bjgso", "comment_Body": "i personally like to do ELT , that means that i load whole dataset from source and store it to stg, then i process all known columns. This, when you keep stg for longer term allows you to implement handling to new columns on your own time frame. This is how i roll it, there is no column renames ( or deletes ,as rename is delete and create new one). Flow is to add new shit , communicate, makes changes to downstream and when some name is no longer in use, it can be removed from source. \n\nIf some column needs to renamed, flow is to add copy of data to new name, communicate, make all changes, and then remove old one. Anything else in inefficient and error prone. \n\nThis also allows development model where small changes can be pushed to production constantly and this allows downstream to catch up to changes on every layer on their time frame. There is problems if adding new column causes any concerns that old stuff stops to work. \n\nthis comes from sql side experience, but it is same for all envronments. There is challenges in datmodel if fields need to renamed constantly. usually adding new one is enough ( except when cleaning is done, that means that interface is no compliant with previous versions which leads to api versioning concept etc etc )", "comment_Score": 1, "comment_Author": "throw_mob", "comment_Link_id": "1cd4p69", "Create Date": "2024-04-26 07:36:20+00:00"}, {"comment_ID": "l1bixbo", "comment_Body": "For a work machine, the only issue I have found is internet security blocking urls needed for package installs. How big an issue this is depends on how competent/overzealous your IT are. I run Ubuntu and usually downloading a .deb and installing from that gets around this.", "comment_Score": 2, "comment_Author": "speedisntfree", "comment_Link_id": "1cdc878", "Create Date": "2024-04-26 07:29:39+00:00"}, {"comment_ID": "l1bibjh", "comment_Body": "20 Years of experience w/ DBT.", "comment_Score": 1, "comment_Author": "FUCKYOUINYOURFACE", "comment_Link_id": "1ccsf39", "Create Date": "2024-04-26 07:22:19+00:00"}, {"comment_ID": "l1bi0ks", "comment_Body": "Isn\u2019t it cheaper to just run a cron job? I don\u2019t understand why people are jumping to cloud solutions on this (which could cost money) but maybe I\u2019m uninformed", "comment_Score": 2, "comment_Author": "Xerionik", "comment_Link_id": "1cd0tmv", "Create Date": "2024-04-26 07:18:44+00:00"}, {"comment_ID": "l1bhb02", "comment_Body": "DWH is thing of the past. Top management can\u2019t see value. Latest trend is dump all data in lakes, Slap the AI sticker and magic will happen!!", "comment_Score": 1, "comment_Author": "SGManto", "comment_Link_id": "1ccsf39", "Create Date": "2024-04-26 07:10:31+00:00"}, {"comment_ID": "l1bgoqj", "comment_Body": "Firm believer the Data Orchestration topic lags the Data Engineering topic as well", "comment_Score": 1, "comment_Author": "engineer_of-sorts", "comment_Link_id": "1ccsf39", "Create Date": "2024-04-26 07:03:27+00:00"}, {"comment_ID": "l1bgk11", "comment_Body": "too late. it's in prod now", "comment_Score": 2, "comment_Author": "firespoon", "comment_Link_id": "1cd0tmv", "Create Date": "2024-04-26 07:01:56+00:00"}, {"comment_ID": "l1bf0rl", "comment_Body": "Dagster. It's a good tool. But I am also interested in Kestra.", "comment_Score": 1, "comment_Author": "peekaboo1412", "comment_Link_id": "1ccueqx", "Create Date": "2024-04-26 06:44:30+00:00"}, {"comment_ID": "l1baudk", "comment_Body": "> My question is do you have to be on-call as a Data Engineer?\n\nDepends on:\n\n1. The company tech organization: are \"devops admins\" going to support your production environment or do you have to do it yourself?\n2. Is your data served to external clients?: if your clients are the nearby team, you can just chat with them if there's an issue and you can probably solve it after the weekend. But if it appears in a client app over the weekend, you'll probably have to support it on weekend to avoid customer backslash.\n3. What your contract mentions.\n\nMost of my jobs, I didn't have to do that, but currently I have to and I hate it.\n\nI think you can quite easily ask those questions during the interviews and decide if the cost/benefit is good for you. In my case, there was a notable benefit that made me accept the cost.", "comment_Score": 1, "comment_Author": "sib_n", "comment_Link_id": "1cd6v3c", "Create Date": "2024-04-26 05:59:12+00:00"}, {"comment_ID": "l1bal4c", "comment_Body": "Big fan of Temporal, also Hatchet looks promising", "comment_Score": 1, "comment_Author": "BigCaregiver7285", "comment_Link_id": "1ccueqx", "Create Date": "2024-04-26 05:56:32+00:00"}, {"comment_ID": "l1bajve", "comment_Body": "1. Data Engineer\n2. 5 years fulltime 2 years parttime\n3. Netherlands\n4. 90k plus 1k monthly lease budget euro\n5. 10k euro bonus end year\n6. Worked for railways and energy markets.\n7. Azure, docker, functions, adf, containers, terraform, snowflake", "comment_Score": 1, "comment_Author": "Present_Tradition_24", "comment_Link_id": "1b3zatv", "Create Date": "2024-04-26 05:56:11+00:00"}, {"comment_ID": "l1badnm", "comment_Body": "https://community.sap.com/t5/technology-blogs-by-sap/guidance-for-partners-on-certifying-their-data-integration-offerings-with/ba-p/13578551\n\n\u201cUsage of ODP RFC API: For real-time integration with external applications the usage of RFC modules of the Operational Data Provisioning (ODP) Data Replication API by customers or third-party applications is NOT permitted, as documented in SAP Note 3255746.Similarly, usage of other unreleased RFCs directly or via OData/Webservices is not a recommended integration approach\u201d\n\n\ud83d\ude44", "comment_Score": 1, "comment_Author": "Remote_Temperature", "comment_Link_id": "1ccv2r3", "Create Date": "2024-04-26 05:54:21+00:00"}, {"comment_ID": "l1ba287", "comment_Body": "WSL is great. yes you can run GUI apps in it. no complaints. make sure to download the windows terminal app and you will be good to go", "comment_Score": 4, "comment_Author": "EnthusiasticRetard", "comment_Link_id": "1cdc878", "Create Date": "2024-04-26 05:51:00+00:00"}, {"comment_ID": "l1b8ri7", "comment_Body": "The features I need are a security and high volume storage:\n\na) I will get a bulk of for example 3600 entries that I need to push to the db. \nb) Furthermore, location data per user will be stored to see if  another user is nearby. \nc) And the chats between two users/group will be stored, but I am not sure if that needs to be in the NoSQL.\n\nUpdates are less likely, data gets stored and get queried.\n\nThe frequency of sending large pieces of data (I.e. 3600+ records will happen often. \n\nSecurity is really important - that\u2019s a no brainer for me.", "comment_Score": 1, "comment_Author": "__bdude", "comment_Link_id": "1cd1ce6", "Create Date": "2024-04-26 05:37:34+00:00"}, {"comment_ID": "l1b8dmm", "comment_Body": "I think traditional BI will come back at some point. There has been an AE hype but there is still not a lot of jobs opening (vs more heavy technical DE). I think a lot of companies start to have robust data infrastructures, but when you look at the schema, tables (sometimes no data warehouse, shitty data marts) you start to cry \u2026 so BI to clean this mess with governance.", "comment_Score": 2, "comment_Author": "His0kx", "comment_Link_id": "1ccsf39", "Create Date": "2024-04-26 05:33:41+00:00"}, {"comment_ID": "l1b802y", "comment_Body": "Appreciate this response \ud83d\ude4f", "comment_Score": 1, "comment_Author": "Thiseffingguy2", "comment_Link_id": "1cbx8bb", "Create Date": "2024-04-26 05:29:53+00:00"}, {"comment_ID": "l1b7iw4", "comment_Body": "Check Google Cortex. It has the full Modeling out of the shelf. Also, There is an internal SAP table which has all tables and columns with descriptions. Also one with relations. Good luck in your journey.", "comment_Score": 1, "comment_Author": "alexl0ok", "comment_Link_id": "1ccv2r3", "Create Date": "2024-04-26 05:25:03+00:00"}, {"comment_ID": "l1b7h8c", "comment_Body": "You are right, in case of neo4j I need to learn cypher. The plan is to have a regular relational database and for the bigger dat such as location data per user and activity log per second I am looking for NoSQL", "comment_Score": 1, "comment_Author": "__bdude", "comment_Link_id": "1cd1ce6", "Create Date": "2024-04-26 05:24:36+00:00"}, {"comment_ID": "l1b70ns", "comment_Body": "This is not criticism, but i just find it hilarious how in Software Engineering we are always circling between \u201csimple declarative is the only we to make it clean and keep the code complexity in check\u201d, \u201cwe need to parametrize and template that yaml, coz stuff is similar but not the same and how dare you hardcode values in there directly\u201d and lastly: \u201clooks at all this jinja yaml mess, this would be so much easier to just write in python explicitly\u201d \n\nRinse and repeat", "comment_Score": 3, "comment_Author": "exergy31", "comment_Link_id": "1ccueqx", "Create Date": "2024-04-26 05:20:02+00:00"}, {"comment_ID": "l1b642p", "comment_Body": "Yeah, this will be a work machine.", "comment_Score": 3, "comment_Author": "nydasco", "comment_Link_id": "1cdc878", "Create Date": "2024-04-26 05:11:14+00:00"}, {"comment_ID": "l1b6089", "comment_Body": "Dont have the rights for SE11. I will however check se80.co.uk", "comment_Score": 1, "comment_Author": "Ok-Sentence-8542", "comment_Link_id": "1ccv2r3", "Create Date": "2024-04-26 05:10:14+00:00"}, {"comment_ID": "l1b5qf8", "comment_Body": "You will need the following:\nA server to run the code. This can just be your laptop or you can get a server on aws/azure/gcp. Alternatively you can use serverless functions such as Lambda to execute your code.\n\nHonestly for 5000 rows a day, and assuming it is not business critical, I would just run it from my own machine once a day.", "comment_Score": 1, "comment_Author": "SalmonFalls", "comment_Link_id": "1cd0tii", "Create Date": "2024-04-26 05:07:35+00:00"}, {"comment_ID": "l1b4r5d", "comment_Body": "He wants to manually reconcile data", "comment_Score": 1, "comment_Author": "Pillstyr", "comment_Link_id": "1cck5fd", "Create Date": "2024-04-26 04:58:23+00:00"}, {"comment_ID": "l1b4q7i", "comment_Body": "The one who's incharge right now", "comment_Score": 1, "comment_Author": "Pillstyr", "comment_Link_id": "1cck5fd", "Create Date": "2024-04-26 04:58:08+00:00"}, {"comment_ID": "l1b4c84", "comment_Body": "I have a decade of experience in the data industry, with the past few years focused on data engineering. Although this role has been both enjoyable and challenging, it sometimes involves demanding clients and extended working hours due to project deadlines. While my contracts often require legal exemptions from standard working hours to meet client demands, this typically means only occasional weekend or evening work to push projects over the finish line. Fortunately, such situations are rare when you're part of a supportive company and team. Otherwise I enjoy my job and find it fulfilling.", "comment_Score": 1, "comment_Author": "ABigTongue", "comment_Link_id": "1cd6v3c", "Create Date": "2024-04-26 04:54:35+00:00"}, {"comment_ID": "l1b48ke", "comment_Body": "Your post/comment was removed because it violated rule #3 (Do a search before asking a question). The question you asked has been answered in the wiki so we remove these questions to keep the feed digestable for everyone.", "comment_Score": 1, "comment_Author": "dataengineering-ModTeam", "comment_Link_id": "1cd5gzc", "Create Date": "2024-04-26 04:53:39+00:00"}, {"comment_ID": "l1b3qvp", "comment_Body": "Potentially, but I\u2019m assuming that would be a bigger memory constraint.", "comment_Score": 1, "comment_Author": "nydasco", "comment_Link_id": "1cdc878", "Create Date": "2024-04-26 04:49:10+00:00"}, {"comment_ID": "l1b3mb6", "comment_Body": "This post was flagged as not being related enough to data engineering. In order to keep the quality and engagement high, we sometimes remove content that is unrelated or not relevant enough to data engineering.", "comment_Score": 1, "comment_Author": "dataengineering-ModTeam", "comment_Link_id": "1cdb4at", "Create Date": "2024-04-26 04:48:00+00:00"}, {"comment_ID": "l1b0i9x", "comment_Body": "Data Toilets", "comment_Score": 2, "comment_Author": "johntheswan", "comment_Link_id": "1ccsf39", "Create Date": "2024-04-26 04:21:20+00:00"}]