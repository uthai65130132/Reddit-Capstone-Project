[{"comment_ID": "l1akj7i", "comment_Body": "That\u2019s what I was thinking.", "comment_Score": 1, "comment_Author": "JBalloonist", "comment_Link_id": "1cd0tmv", "Create Date": "2024-04-26 02:24:46+00:00"}, {"comment_ID": "l1ajtth", "comment_Body": "It's honestly good to know that other people are feeling the same. I am an analyst and work with sap Hana, such a frustrating experience. Impossible view and tables names, no functions available besides the really basic ones, slow and limited connectivity...", "comment_Score": 1, "comment_Author": "GBrownianMotion", "comment_Link_id": "1ccv2r3", "Create Date": "2024-04-26 02:20:11+00:00"}, {"comment_ID": "l1ajgon", "comment_Body": "GitHub Actions scheduled workflow. Completely free and with their secrets you can safely handle your database credentials", "comment_Score": 1, "comment_Author": "Luxi36", "comment_Link_id": "1cd0tmv", "Create Date": "2024-04-26 02:17:50+00:00"}, {"comment_ID": "l1aj9g0", "comment_Body": ">orchestration in MSDOS batch scripts\n\ndaayyuum duuude", "comment_Score": 1, "comment_Author": "ab624", "comment_Link_id": "1ccueqx", "Create Date": "2024-04-26 02:16:31+00:00"}, {"comment_ID": "l1aiil6", "comment_Body": "Most DE roles do not include on-call. You won\u2019t really see on-call work unless you work with real-time data streaming that are pretty critical to the core business group.", "comment_Score": 1, "comment_Author": "Xtrerk", "comment_Link_id": "1cd6v3c", "Create Date": "2024-04-26 02:11:40+00:00"}, {"comment_ID": "l1ahng6", "comment_Body": "Start by pivoting and working on the value proposition. \n\nWhat are you trying to create and what is the value to your org and stakeholders / budget holders? \n\nIf you're trying to bring sanity to chaos (custom r shiny, no ownership of data, slow response times) then find a limited scope project where you can try out how you would handle that. Then present, pitch and showcase for your stakeholders and present the value add for a budget against this. \n\n>\"So far all I've done is automate a few pipelines to pull/transform data from SSMS with ADF and then use Logic Apps to drop csv in an external SFTP server. I've started curating data marts by creating Azure SQL Db tables to extract and house only our data from the 3rd party org in semi-functional Datamarts but these seem lateral at best.\" \n\nThis should happen so far down into this project that you're starting at the wrong place.  You can build data marts and do all your modeling anywhere and then move it into the cloud when that's required. Not at the start of things.", "comment_Score": 1, "comment_Author": "Separate-Cycle6693", "comment_Link_id": "1ccy0s6", "Create Date": "2024-04-26 02:06:09+00:00"}, {"comment_ID": "l1ahj1d", "comment_Body": "while data engineering serves pipelines that bring forth information that data science models consume, both falls within analytics and are members of artificial intelligence that is powered by data in its raw collected format. I find data engineering more challenging and vast due to it effect on enterpsrise data ecosystem while data science is a module within and non-informed of origin, lineage or effectiveness of data. \n\nYou can also pivot vertically and assume roles of data architects or the chief data officer for what its worth.\n\naimmaz :)", "comment_Score": 1, "comment_Author": "aimmaz", "comment_Link_id": "1cd6v3c", "Create Date": "2024-04-26 02:05:22+00:00"}, {"comment_ID": "l1ahha0", "comment_Body": "I have a friend who is doing very well teaching AP level English there, but I can't do that. I am an engineer.", "comment_Score": 1, "comment_Author": "fxzkz", "comment_Link_id": "1bt7iv2", "Create Date": "2024-04-26 02:05:03+00:00"}, {"comment_ID": "l1agt5o", "comment_Body": "One thing to check if choosing duckdb is the concurrency model. https://duckdb.org/docs/connect/concurrency.html", "comment_Score": 1, "comment_Author": "rwilldred27", "comment_Link_id": "1ccs3vs", "Create Date": "2024-04-26 02:00:42+00:00"}, {"comment_ID": "l1ag6m7", "comment_Body": "Nah, Amundsen is outdated as per my benchmarks. \nDatahub is way ahead.\nNo, i dont think it is cost, i think they dont understand the value in it since they dont deal with day to day friction", "comment_Score": 1, "comment_Author": "InsightByte", "comment_Link_id": "1cd8xbl", "Create Date": "2024-04-26 01:56:45+00:00"}, {"comment_ID": "l1afln9", "comment_Body": "Is it a cost thing?  If so, why not Amundsen?", "comment_Score": 1, "comment_Author": "ShrekOne2024", "comment_Link_id": "1cd8xbl", "Create Date": "2024-04-26 01:53:05+00:00"}, {"comment_ID": "l1afl57", "comment_Body": "Same. I have no reason to move out of Airflow, works pretty nice for us. I could be wrong, but maybe the issues people have with Airflow could be related to how it is deployed? Like, if you run operators on the same machine as Airflow things could get nasty.", "comment_Score": 1, "comment_Author": "Substantial-Cow-8958", "comment_Link_id": "1ccueqx", "Create Date": "2024-04-26 01:52:59+00:00"}, {"comment_ID": "l1aeoiq", "comment_Body": "Flair is hilarious", "comment_Score": 1, "comment_Author": "krurran", "comment_Link_id": "1ccsf39", "Create Date": "2024-04-26 01:47:19+00:00"}, {"comment_ID": "l1aec2q", "comment_Body": "You are more likely to be on call as a DE then as a DS but it's not guaranteed. I wasn't on call my last job though and it was pretty annoying, I will definitely admit that. I do think that there's a very good argument to pick data engineering as I think that there's a lot less competition and more jobs, most places need five data engineers for every one or two data scientists or ML engineers", "comment_Score": 1, "comment_Author": "gray_grum", "comment_Link_id": "1cd6v3c", "Create Date": "2024-04-26 01:45:07+00:00"}, {"comment_ID": "l1aec2p", "comment_Body": "Perfect!  Thank you for the response!  I will research this and try to present at least the basics in the meeting and hope I get further than \u201cthere is no solution\u201d.", "comment_Score": 1, "comment_Author": "sdsmith0610", "comment_Link_id": "1cd3saf", "Create Date": "2024-04-26 01:45:07+00:00"}, {"comment_ID": "l1ae2iy", "comment_Body": "I did a proof of concept rag project on that requirements doc effort I mentioned above. It worked darn well, but MGMT didn't want to proceed with it because we would have to buy servers to keep everything local and the scale was cost prohibitive for their liking. \n\nYou could get a $3k desktop to run for a small 5 person team. \n\nContracts would basically be the same use case except more documents. I would contextualize groups of contracts so it wouldn't get too unruly.", "comment_Score": 1, "comment_Author": "Swirls109", "comment_Link_id": "1ccdveg", "Create Date": "2024-04-26 01:43:29+00:00"}, {"comment_ID": "l1adcb7", "comment_Body": "This happened 3 times to me in consulting all 3 times the JD dropped all kinds of buzz words and tech stacks I was a bit intimidated. Meanwhile it was a few people at different locations manually inputting sensor data into excel. (Imbed loud fart sound here\u2026)\ud83d\udca8\ud83d\ude02", "comment_Score": 1, "comment_Author": "soundboyselecta", "comment_Link_id": "1ccsf39", "Create Date": "2024-04-26 01:39:02+00:00"}, {"comment_ID": "l1ad0kx", "comment_Body": "I think that's a common aspect of any backend and infrastructure engineering, system administrators complain about that all the time.", "comment_Score": 1, "comment_Author": "sib_n", "comment_Link_id": "1ccsf39", "Create Date": "2024-04-26 01:37:06+00:00"}, {"comment_ID": "l1acmiu", "comment_Body": "We are upgrading to ocean, brace yourself.", "comment_Score": 2, "comment_Author": "sib_n", "comment_Link_id": "1ccsf39", "Create Date": "2024-04-26 01:34:45+00:00"}, {"comment_ID": "l1aaymb", "comment_Body": "So is this why they keep inventing new positions\u2026every week.", "comment_Score": 1, "comment_Author": "soundboyselecta", "comment_Link_id": "1ccsf39", "Create Date": "2024-04-26 01:24:28+00:00"}, {"comment_ID": "l1aaozc", "comment_Body": "Team Susan \ud83d\ude02", "comment_Score": 1, "comment_Author": "soundboyselecta", "comment_Link_id": "1ccsf39", "Create Date": "2024-04-26 01:22:50+00:00"}, {"comment_ID": "l1a9pjp", "comment_Body": "Works as designed. Design sucks.", "comment_Score": 2, "comment_Author": "lzwzli", "comment_Link_id": "1ccv2r3", "Create Date": "2024-04-26 01:16:47+00:00"}, {"comment_ID": "l1a90rr", "comment_Body": "Or both", "comment_Score": 5, "comment_Author": "lzwzli", "comment_Link_id": "1ccv2r3", "Create Date": "2024-04-26 01:12:39+00:00"}, {"comment_ID": "l1a7o1i", "comment_Body": "You can find a list of community-submitted learning resources here: https://dataengineering.wiki/Learning+Resources\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dataengineering) if you have any questions or concerns.*", "comment_Score": 1, "comment_Author": "AutoModerator", "comment_Link_id": "1cd8bs7", "Create Date": "2024-04-26 01:04:34+00:00"}, {"comment_ID": "l1a76xv", "comment_Body": "Depends on the team for DE. Sometimes there's on-call but the load won't be as high as Ops / Sysadmin, because you're just responsible for your own infra, not the whole company's infra.\n\nDS analysts generally don't have to be on call since they usually don't write critical production code.", "comment_Score": 2, "comment_Author": "dravacotron", "comment_Link_id": "1cd6v3c", "Create Date": "2024-04-26 01:01:33+00:00"}, {"comment_ID": "l1a6qwo", "comment_Body": "Interested in DE so I really hope so", "comment_Score": 1, "comment_Author": "snailspeed25", "comment_Link_id": "1ccsf39", "Create Date": "2024-04-26 00:58:47+00:00"}, {"comment_ID": "l1a6qpu", "comment_Body": "More face time with leaders who don't have the slightest understanding of the complexity under the hood. All they see is fancy dashboards and presentations and assume it's easy", "comment_Score": 3, "comment_Author": "Hackerjurassicpark", "comment_Link_id": "1ccsf39", "Create Date": "2024-04-26 00:58:45+00:00"}, {"comment_ID": "l1a6l5o", "comment_Body": "Given these requirements and the consensus on postgres as a DB I think Mageai is worth consideration. \n\n1. It's easy to get started as it's just a docker image.\n2. It has a lot of out of the box loaders, transformers and exporters for common tools ie postgres.\n3. You just drag blocks onto the canvas, connect them by dragging lines between blocks and schedule it with a trigger. \n4. They have a pretty good slack community for help and support. It also has a bot that you can ask questions.", "comment_Score": 1, "comment_Author": "wannabe-DE", "comment_Link_id": "1ccs3vs", "Create Date": "2024-04-26 00:57:47+00:00"}, {"comment_ID": "l1a6eb0", "comment_Body": "This is the way. Also doable in Azure and GCP.", "comment_Score": 1, "comment_Author": "corecursion0", "comment_Link_id": "1cd0tii", "Create Date": "2024-04-26 00:56:36+00:00"}, {"comment_ID": "l1a69e6", "comment_Body": "It\u2019s easy if you want to teach English.  If not, not so much.  I make a fair amount more than my wife teaching but we have been here a long time and want to get out.  Thanks", "comment_Score": 1, "comment_Author": "Bare_arms", "comment_Link_id": "1bt7iv2", "Create Date": "2024-04-26 00:55:46+00:00"}, {"comment_ID": "l1a5pbl", "comment_Body": "Also, this thread details how I've circumvented the coupling of both selecting a group of dbt models and defining how they're to be computed.\n\n[https://github.com/dagster-io/dagster/discussions/20761](https://github.com/dagster-io/dagster/discussions/20761)\n\nTo provide an example of the problem:\n\n* you load in a group of upstream models (staging for example) with one dbt\\_assets decorator\n* you load in a second group of downstream models (marts for example) with one dbt\\_assets decorator.\n* If ANY of the upstream models (assets in dagster) fail, NONE of the downstream models (assets) will run\n* This is because each dbt\\_assets decorator constructs only one dbt command to be executed.\n* Thus, with the current dagster\\_dbt API, the dbt command to be executed is not dynamic and cannot subset models to run\n* To circumvent this, I used a asset factory to create one dbt\\_assets decorator per model by parsing the dbt\\_manifest.json manually", "comment_Score": 1, "comment_Author": "coreytrevorlahey69", "comment_Link_id": "1aqvhcj", "Create Date": "2024-04-26 00:52:20+00:00"}, {"comment_ID": "l1a4k0q", "comment_Body": "get out if you can", "comment_Score": 1, "comment_Author": "jaylen_browns_beard", "comment_Link_id": "1ccv2r3", "Create Date": "2024-04-26 00:45:14+00:00"}, {"comment_ID": "l1a47ye", "comment_Body": "Sorry, edited the comment above.", "comment_Score": 1, "comment_Author": "coreytrevorlahey69", "comment_Link_id": "1aqvhcj", "Create Date": "2024-04-26 00:43:06+00:00"}, {"comment_ID": "l1a4691", "comment_Body": "Your contract example is \\*very\\* interesting.  Is that something you've worked with before?", "comment_Score": 1, "comment_Author": "CalendarSpecific1088", "comment_Link_id": "1ccdveg", "Create Date": "2024-04-26 00:42:47+00:00"}, {"comment_ID": "l1a45vh", "comment_Body": "Would love a link to that thread! \n\nEdit: Amazing username BTW", "comment_Score": 1, "comment_Author": "noah-ford", "comment_Link_id": "1aqvhcj", "Create Date": "2024-04-26 00:42:43+00:00"}, {"comment_ID": "l1a40s6", "comment_Body": "Funny you mention.  I've had long arguments with Copilot about how it outright lies describing what my company does, which it apologizes for and then doubles down the mis-statement.\n\nI'll concede effectiveness on tonal language assistance (you can sound much more professional), but that's about it.  In other words, LLM's are good at assisting with the English language (assuming that's your LLM's language); anything else is patchy.  \n\nAI's give you a statement that's statistically likely to be said.  Since the internet has a high degree of bullshit, you can infer the inevitable results.", "comment_Score": 1, "comment_Author": "CalendarSpecific1088", "comment_Link_id": "1ccdveg", "Create Date": "2024-04-26 00:41:48+00:00"}, {"comment_ID": "l1a40hu", "comment_Body": "I've actually made lots of progress with automaterialization. I created this thread yesterday on the dagster github that was quickly answered by a maintainer. \n\n[https://github.com/dagster-io/dagster/discussions/21400](https://github.com/dagster-io/dagster/discussions/21400)\n\nThe thread outlines at a high level how I'm using automaterialization with both non-partitioned and partitioned assets. I actually don't specify anything about automaterialization in the dbt yml files, and entierly handle it within the dagster code base.\n\nI'm also happy to share any knowledge if you have any questions!", "comment_Score": 1, "comment_Author": "coreytrevorlahey69", "comment_Link_id": "1aqvhcj", "Create Date": "2024-04-26 00:41:45+00:00"}, {"comment_ID": "l1a3rtl", "comment_Body": "> C-suite wants some performance and financial data\n\nBefore implementing, some things to consider:\n- how frequently will the data be updated?\n- who is the end consumer of the Data? Usually Finance just wants the raw data and wants to manipulate/chart themselves.\n- what\u2019s the volume of data? \n\nHonestly, from my experience, based on what you said, your implementation seems like overkill. If you wanna develop the skills, go for it. Otherwise, just (export to CSV) and import into Google Sheets. [Here\u2019s a link to SO on how to export](https://stackoverflow.com/questions/8119297/postgresql-export-resulting-data-from-sql-query-to-excel-csv). Just cron this and dump to a shared folder. \n\nIf you have Excel, even better. There are commercial ODBC drivers that will let you connect directly to Postgres.", "comment_Score": 1, "comment_Author": "jawabdey", "comment_Link_id": "1ccs3vs", "Create Date": "2024-04-26 00:40:13+00:00"}, {"comment_ID": "l1a3pw2", "comment_Body": "Can you give an example?", "comment_Score": 1, "comment_Author": "icysandstone", "comment_Link_id": "1ccsf39", "Create Date": "2024-04-26 00:39:52+00:00"}, {"comment_ID": "l1a3m93", "comment_Body": "What\u2019s after DE so I can jump the line?", "comment_Score": 1, "comment_Author": "icysandstone", "comment_Link_id": "1ccsf39", "Create Date": "2024-04-26 00:39:14+00:00"}]