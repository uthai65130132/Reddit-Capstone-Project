[{"comment_ID": "l16cmjj", "comment_Body": "Hello,\n\nYou can find all the recommendations for preparing for the [DENODO PLATFORM 8.0 DEVELOPER ASSOCIATE](https://community.denodo.com/certification/details?name=Denodo%20Platform%208.0%20Certified%20Developer%20Associate) exam in this [link](https://community.denodo.com/certification/prepare/denodo-platform-80-certified-developer-associate-exam). The preparation time can vary significantly depending on your previous experience and your study pace. Generally, it's recommended to spend about 1 to 3 months preparing to feel comfortable with the material. Also, the results of the exam are available immediately after completion.\n\nHope this helps!", "comment_Score": 1, "comment_Author": "deno2bko", "comment_Link_id": "1bt7heq", "Create Date": "2024-04-25 09:25:10+00:00"}, {"comment_ID": "l16c8vm", "comment_Body": "I will be messaging you in 7 days on [**2024-05-02 09:19:36 UTC**](http://www.wolframalpha.com/input/?i=2024-05-02%2009:19:36%20UTC%20To%20Local%20Time) to remind you of [**this link**](https://www.reddit.com/r/dataengineering/comments/1cc2cl9/should_i_store_my_gold_layer_data_in_a_database/l16c6gn/?context=3)\n\n[**CLICK THIS LINK**](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5Bhttps%3A%2F%2Fwww.reddit.com%2Fr%2Fdataengineering%2Fcomments%2F1cc2cl9%2Fshould_i_store_my_gold_layer_data_in_a_database%2Fl16c6gn%2F%5D%0A%0ARemindMe%21%202024-05-02%2009%3A19%3A36%20UTC) to send a PM to also be reminded and to reduce spam.\n\n^(Parent commenter can ) [^(delete this message to hide from others.)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Delete%20Comment&message=Delete%21%201cc2cl9)\n\n*****\n\n|[^(Info)](https://www.reddit.com/r/RemindMeBot/comments/e1bko7/remindmebot_info_v21/)|[^(Custom)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5BLink%20or%20message%20inside%20square%20brackets%5D%0A%0ARemindMe%21%20Time%20period%20here)|[^(Your Reminders)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=List%20Of%20Reminders&message=MyReminders%21)|[^(Feedback)](https://www.reddit.com/message/compose/?to=Watchful1&subject=RemindMeBot%20Feedback)|\n|-|-|-|-|", "comment_Score": 1, "comment_Author": "RemindMeBot", "comment_Link_id": "1cc2cl9", "Create Date": "2024-04-25 09:20:25+00:00"}, {"comment_ID": "l16c6gn", "comment_Body": "RemindMe! 7 days", "comment_Score": 1, "comment_Author": "shreyas_valake", "comment_Link_id": "1cc2cl9", "Create Date": "2024-04-25 09:19:36+00:00"}, {"comment_ID": "l16bsa7", "comment_Body": "I'm missing a \"why\" here. Why do you want to have other software/tech to do the ETL? What issues are you running into that makes you want to do this move? \n\nThese need to be made clear in order to know what solution would solve these issues for you. \n\nJust moving to another stack for the sake of moving, is only recommended if you need to give yourself more job security.", "comment_Score": 1, "comment_Author": "Zyklon00", "comment_Link_id": "1cck5fd", "Create Date": "2024-04-25 09:14:39+00:00"}, {"comment_ID": "l16aqq2", "comment_Body": "tbh its using for MS Fabric, since the Fabric does not meet to well with open-source things and flexible ways to handle it. And on Fabric, it will be easy to use parquet as well as set up spark for doing this. So I just want a confirmation! or some advices.", "comment_Score": 1, "comment_Author": "sebastiandang", "comment_Link_id": "1ccian9", "Create Date": "2024-04-25 09:01:29+00:00"}, {"comment_ID": "l16aqd3", "comment_Body": "I wrote the code and UI for the old Excel exporter, it had headings, formatting, logo, timestamps, source URL etc.\n\nNow, on the shiny new thing, it's a plain CSV, clients complain that the numbers are wrong and all the usual issues arise.  Date formats / month names / number formatting standards around the world are different and CSV does not have that information.  Also, CSVs are a lot larger than .xlsb files, so the download is noticeably slower.", "comment_Score": 1, "comment_Author": "Little_Kitty", "comment_Link_id": "1ccdveg", "Create Date": "2024-04-25 09:01:22+00:00"}, {"comment_ID": "l16afnk", "comment_Body": "This is awesome - so glad it is readily available for everyone!", "comment_Score": 1, "comment_Author": "Savabg", "comment_Link_id": "1cbx9ki", "Create Date": "2024-04-25 08:57:39+00:00"}, {"comment_ID": "l169vz0", "comment_Body": "Thanks, will check it out!", "comment_Score": 1, "comment_Author": "Siddboss195803", "comment_Link_id": "1cclunj", "Create Date": "2024-04-25 08:50:45+00:00"}, {"comment_ID": "l169meh", "comment_Body": ".xlsx obviously", "comment_Score": 1, "comment_Author": "In_Dust_We_Trust", "comment_Link_id": "1cbx8bb", "Create Date": "2024-04-25 08:47:22+00:00"}, {"comment_ID": "l169ki3", "comment_Body": "I've looked into this question a bit as well but not reached a conclusion, so consider this a discussion starter rather than advice.\n\nWhat do you mean by \"store in a parquet format\"? If you mean a single column with each row being a log line, I'm not sure I see the benefit. It would be a high cardinality column with no repeated values - based on my understanding of parquet's columnar storage and therefore compression no benefit would be achieved (if someone understand it better can correct me please do, parquet specification is a topic that I find difficult to get info on).\n\nOn the other hand, if the logs are broken up into fields that nicely map to columns (as in you've manually done what splunk does automatically) then parquet could be a huge boon for fast filtering/aggregation.\n\nIf you don't have a nicely formatted table, my gut instinct is hudi/arvo as a row based format. That way you may get some binary format benefits. Otherwise if you have a table with some densely filled columns (like timestamp and event type) and then a bunch of sparse columns depending, perhaps a wide column store?", "comment_Score": 1, "comment_Author": "Blue__Dingo", "comment_Link_id": "1ccian9", "Create Date": "2024-04-25 08:46:41+00:00"}, {"comment_ID": "l167lzn", "comment_Body": "I learned the basics from him https://youtu.be/dl00fOOYLOM?si=KGFX-rREkAofTpMr. Then googled topics read resources more deeply", "comment_Score": 2, "comment_Author": "chaachans", "comment_Link_id": "1cclunj", "Create Date": "2024-04-25 08:21:53+00:00"}, {"comment_ID": "l1679dl", "comment_Body": "> Train your behavioural interview skills. Not enough room to talk in detail about this but the industry is full of idiots who insist that they were granted enough Professor X mindreading powers to be able to judge your character purely from your storytelling abilities so make up some fairy tales and rehearse them and you should be good to go\n\nSo much this!  It's the same skill you use when presenting your work, convincing others.  Persuasion, storytelling and building engagement are skills which can be trained and you'll stand out for.  Without training though, good luck getting through an interview.", "comment_Score": 1, "comment_Author": "Little_Kitty", "comment_Link_id": "1ccd1ep", "Create Date": "2024-04-25 08:17:30+00:00"}, {"comment_ID": "l16739d", "comment_Body": "How do you do documentation via Apache Atlas?", "comment_Score": 1, "comment_Author": "deliosenvy", "comment_Link_id": "1ccdveg", "Create Date": "2024-04-25 08:15:20+00:00"}, {"comment_ID": "l165kik", "comment_Body": "Ah TIL, ty!", "comment_Score": 1, "comment_Author": "TheBurgerflip", "comment_Link_id": "1cbx8bb", "Create Date": "2024-04-25 07:56:18+00:00"}, {"comment_ID": "l1659nv", "comment_Body": "Nerd == money", "comment_Score": 1, "comment_Author": "Happy-Hornet622", "comment_Link_id": "1cc9gh3", "Create Date": "2024-04-25 07:52:35+00:00"}, {"comment_ID": "l164iut", "comment_Body": "Fabric isn't a bad offering considering you are currently the meat in the Microsoft sandwich. It's still very much in it's infancy and you *will* experience blockers you need to work around whilst they implement some very commonly used bits on the TSQL side.", "comment_Score": 1, "comment_Author": "fLu_csgo", "comment_Link_id": "1cck5fd", "Create Date": "2024-04-25 07:43:29+00:00"}, {"comment_ID": "l163q3y", "comment_Body": "Can you try this link? It \\*may\\* bypass the limit: [https://medium.com/@nydas/an-opinionated-guide-to-layering-your-analytics-and-reporting-pipelines-b1d8a510b671?source=friends\\_link&sk=d25d8f42c2e3f30b240861c94b232241](https://medium.com/@nydas/an-opinionated-guide-to-layering-your-analytics-and-reporting-pipelines-b1d8a510b671?source=friends_link&sk=d25d8f42c2e3f30b240861c94b232241)", "comment_Score": 2, "comment_Author": "nydasco", "comment_Link_id": "1ccd6rs", "Create Date": "2024-04-25 07:33:39+00:00"}, {"comment_ID": "l163oqz", "comment_Body": "Would you mind checking if this link works? It may bypass the 'max visits for unpaid accounts' limit: [https://medium.com/@nydas/an-opinionated-guide-to-layering-your-analytics-and-reporting-pipelines-b1d8a510b671?source=friends\\_link&sk=d25d8f42c2e3f30b240861c94b232241](https://medium.com/@nydas/an-opinionated-guide-to-layering-your-analytics-and-reporting-pipelines-b1d8a510b671?source=friends_link&sk=d25d8f42c2e3f30b240861c94b232241)", "comment_Score": 2, "comment_Author": "nydasco", "comment_Link_id": "1ccd6rs", "Create Date": "2024-04-25 07:33:11+00:00"}, {"comment_ID": "l163d1j", "comment_Body": "Tbh, Medium comes up a lot in my searches and appears to have quality content, but it seems like the site allows one free article a month, so I usually end up skipping any content they have.", "comment_Score": 1, "comment_Author": "MachineParadox", "comment_Link_id": "1ccd6rs", "Create Date": "2024-04-25 07:29:14+00:00"}, {"comment_ID": "l1630v5", "comment_Body": "Interesting point on number one. I can definitely see some divergence in how engines add additional metadata to parquet. \n\nI reckon that is just because a standard for enhanced file metrics between engines hasn\u2019t really matured yet.", "comment_Score": 1, "comment_Author": "IfIFuckThisModel", "comment_Link_id": "1cbx8bb", "Create Date": "2024-04-25 07:25:10+00:00"}, {"comment_ID": "l162x0b", "comment_Body": "Motherduck/duckdb, dagster cloud. Polars when they have something to sell. Google Cloud Platform\u00a0", "comment_Score": 2, "comment_Author": "DynamicCast", "comment_Link_id": "1cc9gh3", "Create Date": "2024-04-25 07:23:54+00:00"}, {"comment_ID": "l162um7", "comment_Body": "You can find a list of community-submitted learning resources here: https://dataengineering.wiki/Learning+Resources\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dataengineering) if you have any questions or concerns.*", "comment_Score": 1, "comment_Author": "AutoModerator", "comment_Link_id": "1cclunj", "Create Date": "2024-04-25 07:23:06+00:00"}, {"comment_ID": "l162myj", "comment_Body": "That\u2019s shit. Let me see if there is a family access for non-paywalled that doesn\u2019t need an account. Just out with my son at the moment. Otherwise I\u2019m just gonna copy/paste it straight into this thread.", "comment_Score": 2, "comment_Author": "nydasco", "comment_Link_id": "1ccd6rs", "Create Date": "2024-04-25 07:20:38+00:00"}, {"comment_ID": "l162lub", "comment_Body": "Your career? Sit down young person and let me bend your ear a bit.\n\nWell there's internal and external advancement. Internal advancement is pretty chancy, you need to make friends with the right people, and have the right opportunities open up, and somehow not be randomly laid off for multiple years while you build your promotion packet. Too much chance to invest in. So mostly the game is via external advancement. To have the maximum number of options when changing jobs, you need the following:\n\n- Your resume should show impact. If you're writing hand-rolled python scripts that run in an already-existing microservice, that's totally fine - if you can show that the microservice led to business results. Try to avoid maintenance-only teams, like maintaining bog standard SQL or just keeping the existing analytics stack running, unless those teams are part of larger cross functional strategic initiatives that will have impact that you can point to supporting.\n\n- You need keywords for the keyword soup, but they don't necessarily have to show up in a production project. Personal projects are fine. They don't have to be big, just large enough to gain experience - like the size of a lab work or home work is fine. \n\n- For technical rounds you just need to demonstrate some level of proficiency. Spark and SQL are not hard and can be learned in a few days.\n\n- Practice Leetcode regularly and never go out of practice.\n\n- Do some study on system design principles. It's not that hard, basic ideas can be covered in a few days.\n\n- Network like crazy. \n\n- Train your behavioral interview skills. Not enough room to talk in detail about this but the industry is full of idiots who insist that they were granted enough Professor X mindreading powers to be able to judge your character purely from your storytelling abilities so make up some fairy tales and rehearse them and you should be good to go. \n\nThat's it, \n\n\"Wait,\" I hear you say, \"That makes no sense. There's hardly anything here about building great software. What about real technical know-how? Having a history of being a good software craftsman? Doesn't that advance your career?\"\n\nNah bro. That's mostly for you. It's the reason why you're doing this and not some finance job. All the above bits just keep the paycheck healthy and the opportunities coming so that you can continue to enjoy writing good code and learning new things. Not the other way around. \n\nI've spent a long time in the industry watching people advance and not advance and learned much too late that it's the meta-game that moves your career forward, and moving the career forward is what benefits the technical game. Some of my peers understood this way early in their careers and now have much more comfortable lives than I will ever see. Hope this helps someone not make the same mistakes that I did.", "comment_Score": 5, "comment_Author": "dravacotron", "comment_Link_id": "1ccd1ep", "Create Date": "2024-04-25 07:20:16+00:00"}, {"comment_ID": "l161xw6", "comment_Body": "Yep signed up previously, but Medium wants me to get a paid subscription.", "comment_Score": 1, "comment_Author": "MachineParadox", "comment_Link_id": "1ccd6rs", "Create Date": "2024-04-25 07:12:24+00:00"}, {"comment_ID": "l161nlj", "comment_Body": "I think it\u2019s mostly Python tbh. Dbt for transform once you\u2019re in the db, but Python to do the extract/load.", "comment_Score": 1, "comment_Author": "nydasco", "comment_Link_id": "1cchtjk", "Create Date": "2024-04-25 07:09:04+00:00"}, {"comment_ID": "l160rm1", "comment_Body": "We haven't discussed a cloud migration yet, but it's a good point to consider.\n\nFor orchestration and storage we use just SQL because the guy doing it is pretty old-school. For analytics we use Power BI.\n\nDon't get me wrong in any way I'm just about to step foot into DE so if any of info provided by me doesn't add up, please do correct me.", "comment_Score": 1, "comment_Author": "Pillstyr", "comment_Link_id": "1cck5fd", "Create Date": "2024-04-25 06:58:58+00:00"}, {"comment_ID": "l160339", "comment_Body": "Data comparison tool that will work both with Snowflake and Sql server and Rds", "comment_Score": 1, "comment_Author": "awkward_period", "comment_Link_id": "1ccdveg", "Create Date": "2024-04-25 06:51:13+00:00"}, {"comment_ID": "l15ymat", "comment_Body": "I\u2019m very new to these tools. are these mainly available for free and not for enterprise (paid) services?", "comment_Score": 0, "comment_Author": "Frequent_Computer583", "comment_Link_id": "1ccd1ep", "Create Date": "2024-04-25 06:34:36+00:00"}, {"comment_ID": "l15x7zu", "comment_Body": "Excel as a Database? lol that sounds legit", "comment_Score": 2, "comment_Author": "Rude-Veterinarian-45", "comment_Link_id": "1ccdveg", "Create Date": "2024-04-25 06:19:09+00:00"}, {"comment_ID": "l15x22e", "comment_Body": "Understand customer purchase/spend behavior before your competition does it and gain advantage!", "comment_Score": 1, "comment_Author": "Rude-Veterinarian-45", "comment_Link_id": "1ccdveg", "Create Date": "2024-04-25 06:17:24+00:00"}, {"comment_ID": "l15wjsg", "comment_Body": "It\u2019s on Medium, so you may need a free account, but it\u2019s not paywalled.", "comment_Score": -1, "comment_Author": "nydasco", "comment_Link_id": "1ccd6rs", "Create Date": "2024-04-25 06:11:56+00:00"}, {"comment_ID": "l15wh3u", "comment_Body": "Shouldn\u2019t be. I get the option of whether to make it members only or not, and this isn\u2019t. It\u2019s free access. *may* require a free sign up. Not 100% sure on that. But definitely not paywalled.", "comment_Score": 0, "comment_Author": "nydasco", "comment_Link_id": "1ccd6rs", "Create Date": "2024-04-25 06:11:08+00:00"}, {"comment_ID": "l15w216", "comment_Body": "Snowflake is great, and their sales reps are sharks. It's probably a great place to work if you're in sales/marketing.", "comment_Score": 2, "comment_Author": "Sorel_CH", "comment_Link_id": "1cc9gh3", "Create Date": "2024-04-25 06:06:47+00:00"}, {"comment_ID": "l15vohq", "comment_Body": "Thank you for detail response!", "comment_Score": 2, "comment_Author": "sebastiandang", "comment_Link_id": "1ccian9", "Create Date": "2024-04-25 06:02:45+00:00"}, {"comment_ID": "l15viwn", "comment_Body": "I am surprised that business people know we exist. Most business user just want their dashboard, and they think it is just connected to the datasources directly.", "comment_Score": 1, "comment_Author": "kilodekilode", "comment_Link_id": "1cc9gh3", "Create Date": "2024-04-25 06:01:05+00:00"}, {"comment_ID": "l15v76b", "comment_Body": "Someone mentioned Kaggle as a tip for free datasets. I haven't tried it myself.\n\nMedallion architecture is all the rage as well, so you could try to find out good practices doing that on BigQuery.\n\nSetting up cost monitoring might be a nice one. Incremental ingestion and transformation would require some simulation, but is also very useful to learn about.", "comment_Score": 1, "comment_Author": "scataco", "comment_Link_id": "1ccfhl8", "Create Date": "2024-04-25 05:57:37+00:00"}, {"comment_ID": "l15v6b2", "comment_Body": "The amount of SAAS offerings that have \u2018we use AI and ML to improve your business\u2019 with no actual information on their LinkedIn account page is insane", "comment_Score": 1, "comment_Author": "ribrien", "comment_Link_id": "1ccdveg", "Create Date": "2024-04-25 05:57:21+00:00"}, {"comment_ID": "l15upnf", "comment_Body": "Sounds good technique and parquet is a good fit! \nHere are a few things to consider: \n\n1. If your log volume is very high, a low-spec application might struggle to keep up with the ingestion rate. \n2. Are you performing any transformations or filtering on the logs before storing them?\n3. How quickly do you need the logs to be available in the Bronze Layer?\n\nFor high-volume logs, consider streaming tools like Apache Kafka or Apache Flume!", "comment_Score": 3, "comment_Author": "Rude-Veterinarian-45", "comment_Link_id": "1ccian9", "Create Date": "2024-04-25 05:52:29+00:00"}, {"comment_ID": "l15unyn", "comment_Body": "Stick with code, if you can. That being said, where's your company migrating to? From on-prem oracle to... ? \n\nAlso, have a look at dbt, since you have an SQL background. That being said, realize that this is a multi-part question. How are you doing orchestration, storage, analytics, the E, L, and the T? \n\nFinally, ELT > ETL as far as I'm concerned.", "comment_Score": 2, "comment_Author": "SintPannekoek", "comment_Link_id": "1cck5fd", "Create Date": "2024-04-25 05:52:00+00:00"}]