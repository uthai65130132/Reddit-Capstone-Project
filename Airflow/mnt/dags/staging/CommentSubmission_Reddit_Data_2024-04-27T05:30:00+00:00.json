[{"comment_ID": "l1guil5", "comment_Body": "Well, IMHO the modelling (DS or analytics for that matter) is where the magic happens... So it's rarely a case of just using tools, else we wouldn't provide any value as data teams (I mean if that's the case: just use the tools, right?)\n\nAnd that's kind of the whole point of what I was saying with \"fullstack data engineering\" => in such a role you're not \"just\" technical. You also have to get to understand the business needs and hence how you might go about it from the data (available or not...), and only then you get into the technical reflexion on how to actually do it.", "comment_Score": 1, "comment_Author": "briceluu", "comment_Link_id": "1ccsf39", "Create Date": "2024-04-27 06:26:30+00:00"}, {"comment_ID": "l1gtpgb", "comment_Body": "Hi\n\n3NF is just a common term used to describe the design methods for OLTP systems.  As a general practice, 3NF is the way most OLTPs are designed (but you can go to higher in normalization).  \n\nA classical dimensional model (each dimension is a single table) is more like 1NF.   However, if you design a dimensional model and incorporate snowflaking you can end up with a 3NF design which is dimensional.", "comment_Score": 1, "comment_Author": "GreyHairedDWGuy", "comment_Link_id": "1cdrhdu", "Create Date": "2024-04-27 06:17:06+00:00"}, {"comment_ID": "l1gtdqk", "comment_Body": "Could you also dm me please", "comment_Score": 1, "comment_Author": "WallResponsible9918", "comment_Link_id": "1b4r198", "Create Date": "2024-04-27 06:13:28+00:00"}, {"comment_ID": "l1gs55z", "comment_Body": "Yeah, if I get a message explaining why they want to connect I might accept. If you ask some questions I normally take the time to answer them, and converse. Maybe a couple times a year I converse with strangers who are figuring out how to get started, but I never accept invites from strangers with nothing in common if they don\u2019t explain why.", "comment_Score": 1, "comment_Author": "dr_craptastic", "comment_Link_id": "1cds5yo", "Create Date": "2024-04-27 05:59:53+00:00"}, {"comment_ID": "l1grqq0", "comment_Body": "RAID is \"Redundant Array of Independent Disks\". It can be either a hardware (RAID controller) or software level configuration. You basically take multiple drives, depending on the RAID level you're using, and the hardware or software divvies up the drives as needed to support the RAID level you've assigned. For instance, RAID 1 is mirroring, which means when you write to a logical volume, you're actually writing it in two physical locations. Your RAID configuration actually handles the mirroring, so you only see one location, but in the background, everything is mirrored on both logical volumes. One drive goes down, you still have a access to everything because of the mirrored volume. But that also means you halve your total storage. This is the most basic level of fault tolerance, and you should aim for a more complete solution like RAID 5 or 6 or 10.\n\nS3 costs are in egress and time. Something stored in glacier is going to be cheaper to just sit there than in standard storage, but if you need access to the file, it will take time to \"thaw\" and make it available. And AWS charges you for network egress (data leaving AWS) to pull it down from S3. 1-2 TB/mo of egress from S3 will cost between $100 and $200 per month.\n\nYour best bet might be looking at one of those cloud storage providers like Backblaze or pics.io. They still use public cloud storage, but larger entities usually get discounts from cloud providers for their business, so they might give you \"Unlimited\" options that are more affordable, but still profitable for them. I would reach out to a few of them directly and ask them about your specific use case and get certain things in writing. Most of them have \"Fair Usage\" guidelines that do put some practical limits on ingress and egress or file sizes or might throttle transfers above a certain amount. So be very explicit about your needs and make sure you read all the fine print.", "comment_Score": 1, "comment_Author": "BuildingViz", "comment_Link_id": "1cdvxow", "Create Date": "2024-04-27 05:55:35+00:00"}, {"comment_ID": "l1gr7ih", "comment_Body": "What kind of data do you sell?", "comment_Score": 2, "comment_Author": "Martekk_", "comment_Link_id": "1ce0ohq", "Create Date": "2024-04-27 05:49:51+00:00"}, {"comment_ID": "l1gqtbz", "comment_Body": "\"personally identifiable information\", to avoid problems with the General Data Protection Regulation - GDPR", "comment_Score": 2, "comment_Author": "Kaze_Senshi", "comment_Link_id": "1ce0ohq", "Create Date": "2024-04-27 05:45:43+00:00"}, {"comment_ID": "l1goqhc", "comment_Body": "for the rest of us mere mortals though... ;)", "comment_Score": 1, "comment_Author": "mailed", "comment_Link_id": "1cdjtn4", "Create Date": "2024-04-27 05:24:07+00:00"}, {"comment_ID": "l1goeev", "comment_Body": "People always fight for the stack they\u2019re most comfortable with and have a background in. It honestly has nothing to do with SQL or Scala or Rust or whatever. The only thing that matters is getting the right data and quality data for data science, analytics and BI.\n\nUnfortunately in this situation, it looks like your coworker had more influence and he won. This is not an uncommon scenario. In my previous job, a senior engineer who had more of a backend engineering background came to our DE team and completely revamped the entire code base that we had written in PySpark into Scala Spark because HE liked functional languages. He was at the company for 25 years and management didn\u2019t question him. So we had to learn Scala. SMH!!", "comment_Score": 1, "comment_Author": "MotherCharacter8778", "comment_Link_id": "1cdjtn4", "Create Date": "2024-04-27 05:20:49+00:00"}, {"comment_ID": "l1gn1nq", "comment_Body": "Agreed", "comment_Score": 1, "comment_Author": "soundboyselecta", "comment_Link_id": "1cdjtn4", "Create Date": "2024-04-27 05:07:27+00:00"}, {"comment_ID": "l1gn148", "comment_Body": "How did you cold call/message people? What was your strategy? I can shoot the shit with anyone but haven't found the best way to get peoplw on the phone/conversing regularly on linkedin", "comment_Score": 1, "comment_Author": "johnsonfrusciante", "comment_Link_id": "1cds5yo", "Create Date": "2024-04-27 05:07:17+00:00"}, {"comment_ID": "l1gmlcv", "comment_Body": "I believe that is build off their data share technology. That shit is lightning fast. I leverage a transactional platform where we purchase media in real time, and I can see my campaign data via a Snowflake AWS datashare in as little as 10 minutes whereas the platforms themselves take hours to update with aggregate indicators. I\u2019ve built dashboards off of this data to QA our buys faster than we could natively in the companies own software.\n\nIt requires almost 0 ETL, just tell SF where to point the table and query away", "comment_Score": 7, "comment_Author": "JimmyTango", "comment_Link_id": "1ce0ohq", "Create Date": "2024-04-27 05:02:59+00:00"}, {"comment_ID": "l1gmf4m", "comment_Body": "They have some differences, but they\u2019re mostly comparable. Some people just don\u2019t want to be on GCP, and Snowflake will deploy anywhere.", "comment_Score": 5, "comment_Author": "thrav", "comment_Link_id": "1ce0ohq", "Create Date": "2024-04-27 05:01:18+00:00"}, {"comment_ID": "l1glk7b", "comment_Body": "This rings true for me. They've got a winning combo for extracting maximum cash from clients:\n\n1. Ready to go solution that cuts down on the number of pesky employees you have to depend on\n2. Cleverly obfuscated pricing that \\*looks\\* like you know what it's going to cost you, when actually you've no idea what the bill is going to be from one month to the next", "comment_Score": 2, "comment_Author": "bree_dev", "comment_Link_id": "1ce0ohq", "Create Date": "2024-04-27 04:53:11+00:00"}, {"comment_ID": "l1glfks", "comment_Body": "Other on-prem versions are even costlier with less performance.", "comment_Score": 0, "comment_Author": "VolTa1987", "comment_Link_id": "1ce0ohq", "Create Date": "2024-04-27 04:51:58+00:00"}, {"comment_ID": "l1gkfw6", "comment_Body": "I'm just starting to work with spark,  but this guy sounds like a pretentious twat. Is he suggesting to eliminate sql from any part of the ingestion process? It seems like a good way to over complicate things.", "comment_Score": 1, "comment_Author": "kkessler1023", "comment_Link_id": "1cdjtn4", "Create Date": "2024-04-27 04:42:50+00:00"}, {"comment_ID": "l1gjksw", "comment_Body": "Management didn't know SQL from shell scripting. IT has always been managed by people who don't understand it.", "comment_Score": 2, "comment_Author": "BarrySix", "comment_Link_id": "1cdjtn4", "Create Date": "2024-04-27 04:34:57+00:00"}, {"comment_ID": "l1gj8v9", "comment_Body": "Thank you. That is great info", "comment_Score": 1, "comment_Author": "Normal-Inspector7866", "comment_Link_id": "1ce0ohq", "Create Date": "2024-04-27 04:31:55+00:00"}, {"comment_ID": "l1giuqk", "comment_Body": "It\u2019s almost always because of three things:\n\n1) Poor data architecture without separation of concerns, eg like letting people query raw data directly. \n\n2) an unnecessarily large amount of transformations and models (I\u2019m looking at you, dbt)\n\n3) Poor SQL syntax because people don\u2019t understand columnar storage of data warehouses.\n\nSnowflake works just fine and with the right set up will be fast and efficient. But it\u2019s also very forgiving and will just throw compute at the three issues above so that your bill will just keep racking up. \n\nSo get a data engineer who understands setting up Snowflake correctly, set guardrails for your transformation layer and teach your analysts good SQL.", "comment_Score": 1, "comment_Author": "Current_Doubt_8584", "comment_Link_id": "1ce0ohq", "Create Date": "2024-04-27 04:28:25+00:00"}, {"comment_ID": "l1gikj3", "comment_Body": "You can limit that with a warehouse and resource monitor\u00a0", "comment_Score": 3, "comment_Author": "Fantastic-Schedule15", "comment_Link_id": "1ce0ohq", "Create Date": "2024-04-27 04:25:51+00:00"}, {"comment_ID": "l1ghwnm", "comment_Body": "Not weird at all. I run a consulting firm, which has a data and IA verticle. I get heaps of randos sending me requests, I accept all of them (unless I can smell some kinda scam). \n\nI've since given advise to people all over the world, all walks of life and all ages. But they all share a common love of working with data, that I can tell.", "comment_Score": 1, "comment_Author": "Additional-Maize3980", "comment_Link_id": "1cds5yo", "Create Date": "2024-04-27 04:19:56+00:00"}, {"comment_ID": "l1ghgdq", "comment_Body": "I haven't done that, but it should work. It's a straightforward process:\n\n* Add the CSV to the seeds\n* Reference the seed model as you would the SQL model", "comment_Score": 1, "comment_Author": "ivanovyordan", "comment_Link_id": "198w13u", "Create Date": "2024-04-27 04:16:01+00:00"}, {"comment_ID": "l1gge2b", "comment_Body": "Cheaper than GBQ. But I don\u2019t like it as much\u2026", "comment_Score": 2, "comment_Author": "UnrealizedLosses", "comment_Link_id": "1ce0ohq", "Create Date": "2024-04-27 04:06:24+00:00"}, {"comment_ID": "l1gg95m", "comment_Body": "Depends on where you are starting from", "comment_Score": 1, "comment_Author": "deemerritt", "comment_Link_id": "1ce0ohq", "Create Date": "2024-04-27 04:05:12+00:00"}, {"comment_ID": "l1gg7vw", "comment_Body": "Wow TIL.", "comment_Score": 9, "comment_Author": "icysandstone", "comment_Link_id": "1ce0ohq", "Create Date": "2024-04-27 04:04:52+00:00"}, {"comment_ID": "l1gg2t5", "comment_Body": "You mean like no star schema? All 3NF?", "comment_Score": 2, "comment_Author": "icysandstone", "comment_Link_id": "1ce0ohq", "Create Date": "2024-04-27 04:03:39+00:00"}, {"comment_ID": "l1gfu8w", "comment_Body": "Until someone runs a rampant query and sucks up all your monthly credit.", "comment_Score": 2, "comment_Author": "MachineParadox", "comment_Link_id": "1ce0ohq", "Create Date": "2024-04-27 04:01:34+00:00"}, {"comment_ID": "l1gfoqs", "comment_Body": "Probably so but DE definitely has on-call as well. I doubt many jobs in this field don\u2019t have on-call.", "comment_Score": 1, "comment_Author": "khaili109", "comment_Link_id": "1cdx354", "Create Date": "2024-04-27 04:00:14+00:00"}, {"comment_ID": "l1gffk0", "comment_Body": "# \u201cIf the only tool you have is a hammer, you tend to see every problem as a nail.\u201d", "comment_Score": 1, "comment_Author": "Sufficient_Exam_2104", "comment_Link_id": "1cdjtn4", "Create Date": "2024-04-27 03:57:57+00:00"}, {"comment_ID": "l1gfem9", "comment_Body": "Python for working with scripting, data, api' and generally anything in data engineering. You need shell scripts for a few things, but keep them simple. Performance wise your pinching pennies using bash and paying dollars for engineers to do the work", "comment_Score": 1, "comment_Author": "doinnuffin", "comment_Link_id": "1cdqz5r", "Create Date": "2024-04-27 03:57:43+00:00"}, {"comment_ID": "l1gfcfc", "comment_Body": "FYI Snowflake employee:\n\nThere are numerous ways to control costs per account, clusters and user levels.\n\nYou can put hard(Shutoff) or soft(warning only) limits x$ per week/month/year:\n1. At account level \n2. At Warehouse or combo of warehouses\n\n\nYou can also put query timeout limits:\n1. Account Level(applies to all users & clusters)\n2. Warehouse Level ( diff timeouts for engineering  vs. Analytics clusters)\n3. User Level \n\nEach lower level will override the others.\n\nThese will prevent excess usage by avoiding run away queries & stopping compute if gets overused.\n\nThere is also BUDGETS feature that you can use to track costs against compute and storage per project.\n\nAccounts have no limits by default. It is in our onboarding deck that we go over with new customers where putting account & query timeout limits is the first thing we recommend. \n\nWe give tools for controlling, reporting & preventing unwanted usage. You just have to put those controls in place.", "comment_Score": 1, "comment_Author": "Mr_Nickster_", "comment_Link_id": "1ce0ohq", "Create Date": "2024-04-27 03:57:12+00:00"}, {"comment_ID": "l1gfbf8", "comment_Body": "You can enable auto management of your delta tables in DLT, which will automatically vacuum and optimize with z-order. It runs as a separate maintenance job with job compute once per day.", "comment_Score": 1, "comment_Author": "SimpleSimon665", "comment_Link_id": "1ce2ojv", "Create Date": "2024-04-27 03:56:57+00:00"}, {"comment_ID": "l1gev21", "comment_Body": "We had a similar tension at our company with BQ billing, and I made it work without imposing any real rules on analysts or stakeholders using the BI tooling.\n\nI was able to cut our BQ bill in about half a while back with constant usage. Basically without talking to anyone or affecting any work, by building custom tooling into our util library that wraps all of our data infra and switching some stuff out in place.\n\nMostly it was dynamically running queries against the alternative billing methods depending on the expected resource consumption profile of that job (memory vs CPU heavy), and designing an abstraction for partially materialized views on top of big log streaming tables that had a lot of different kinds of events that needed real time reporting.\n\nI also added some really basic constraints for partition filter requirements, Bi tool max byte processing limits, but pretty high. Biggest inflections where those two tools up there, switching out billing methods at run time and these weird partially materialized views that were kind of a pain at first but I wrote as a framework and then could just stamp it.\n\nI'm just saying that because those don't necessarily have to be irreconcilable. It's just that, if your leadership really wants both, they have to make the right investments. In my case the CTO was leaning on me and I didn't want the shit to roll downhill and mess up our culture and productivity, so I just told him that hobby horse would cost him a month of messed up productivity, and dealt with it myself to avoid distracting the team.", "comment_Score": 6, "comment_Author": "melodyze", "comment_Link_id": "1ce0ohq", "Create Date": "2024-04-27 03:53:01+00:00"}, {"comment_ID": "l1getjj", "comment_Body": "Company uses it due to sunk cost fallacy.", "comment_Score": 3, "comment_Author": "Sufficient_Exam_2104", "comment_Link_id": "1ce0ohq", "Create Date": "2024-04-27 03:52:40+00:00"}, {"comment_ID": "l1ges6r", "comment_Body": "Expensive compared to what? Not having an extremely valuable DWH that helps drive revenue generating decisions?", "comment_Score": -1, "comment_Author": "yeetsqua69", "comment_Link_id": "1ce0ohq", "Create Date": "2024-04-27 03:52:20+00:00"}, {"comment_ID": "l1geh73", "comment_Body": "It\u2019s also cloud agnostic, just about every tool/connector works with snowflake across all public clouds", "comment_Score": 6, "comment_Author": "Sp00ky_6", "comment_Link_id": "1ce0ohq", "Create Date": "2024-04-27 03:49:42+00:00"}, {"comment_ID": "l1gedv1", "comment_Body": "your coworker is full of crap. I work for a decent sized game company. My job is a lot of SQL. We're using snowflake primarily as our primary database. I just wrote a 700 line stored procedure that curates data from a bunch of different sources into a shiny, relatively simple table. SQL is the language to do this kinda stuff in, especially since it's going to perform pretty well since it runs directly in snowflake.", "comment_Score": 1, "comment_Author": "seleniumdream", "comment_Link_id": "1cdjtn4", "Create Date": "2024-04-27 03:48:54+00:00"}, {"comment_ID": "l1ge8uj", "comment_Body": "doesn\u2019t Dev ops involve being on call more than DE? That would make a difference in career path", "comment_Score": 2, "comment_Author": "Professional_War2996", "comment_Link_id": "1cdx354", "Create Date": "2024-04-27 03:47:44+00:00"}, {"comment_ID": "l1ge84b", "comment_Body": "This is the way. Defend your team like family, but aggressively weed out the untrustworthy and unreliable. Once everyone trusts each other, up, down and sideways, the team flourishes and then deserves a brave advocate.", "comment_Score": 1, "comment_Author": "AncientClumps", "comment_Link_id": "1cdmsrt", "Create Date": "2024-04-27 03:47:33+00:00"}, {"comment_ID": "l1ge4z9", "comment_Body": "which DWH it was ?", "comment_Score": 3, "comment_Author": "Sufficient_Exam_2104", "comment_Link_id": "1ce0ohq", "Create Date": "2024-04-27 03:46:48+00:00"}]