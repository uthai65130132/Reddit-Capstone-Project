[{"comment_ID": "l163d1j", "comment_Body": "Tbh, Medium comes up a lot in my searches and appears to have quality content, but it seems like the site allows one free article a month, so I usually end up skipping any content they have.", "comment_Score": 1, "comment_Author": "MachineParadox", "comment_Link_id": "1ccd6rs", "Create Date": "2024-04-25 07:29:14+00:00"}, {"comment_ID": "l1630v5", "comment_Body": "Interesting point on number one. I can definitely see some divergence in how engines add additional metadata to parquet. \n\nI reckon that is just because a standard for enhanced file metrics between engines hasn\u2019t really matured yet.", "comment_Score": 1, "comment_Author": "IfIFuckThisModel", "comment_Link_id": "1cbx8bb", "Create Date": "2024-04-25 07:25:10+00:00"}, {"comment_ID": "l162x0b", "comment_Body": "Motherduck/duckdb, dagster cloud. Polars when they have something to sell. Google Cloud Platform\u00a0", "comment_Score": 1, "comment_Author": "DynamicCast", "comment_Link_id": "1cc9gh3", "Create Date": "2024-04-25 07:23:54+00:00"}, {"comment_ID": "l162um7", "comment_Body": "You can find a list of community-submitted learning resources here: https://dataengineering.wiki/Learning+Resources\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dataengineering) if you have any questions or concerns.*", "comment_Score": 1, "comment_Author": "AutoModerator", "comment_Link_id": "1cclunj", "Create Date": "2024-04-25 07:23:06+00:00"}, {"comment_ID": "l162myj", "comment_Body": "That\u2019s shit. Let me see if there is a family access for non-paywalled that doesn\u2019t need an account. Just out with my son at the moment. Otherwise I\u2019m just gonna copy/paste it straight into this thread.", "comment_Score": 1, "comment_Author": "nydasco", "comment_Link_id": "1ccd6rs", "Create Date": "2024-04-25 07:20:38+00:00"}, {"comment_ID": "l162lub", "comment_Body": "Your career? Sit down young person and let me bend your ear a bit.\n\nWell there's internal and external advancement. Internal advancement is pretty chancy, you need to make friends with the right people, and have the right opportunities open up, and somehow not be randomly laid off for multiple years while you build your promotion packet. Too much chance to invest in. So mostly the game is via external advancement. To have the maximum number of options when changing jobs, you need the following:\n\n- Your resume should show impact. If you're writing hand-rolled python scripts that run in an already-existing microservice, that's totally fine - if you can show that the microservice led to business results. Try to avoid maintenance-only teams, like maintaining bog standard SQL or just keeping the existing analytics stack running, unless those teams are part of larger cross functional strategic initiatives that will have impact that you can point to supporting.\n\n- You need keywords for the keyword soup, but they don't necessarily have to show up in a production project. Personal projects are fine. They don't have to be big, just large enough to gain experience - like the size of a lab work or home work is fine. \n\n- For technical rounds you just need to demonstrate some level of proficiency. Spark and SQL are not hard and can be learned in a few days.\n\n- Practice Leetcode regularly and never go out of practice.\n\n- Do some study on system design principles. It's not that hard, basic ideas can be covered in a few days.\n\n- Network like crazy. \n\n- Train your behavioral interview skills. Not enough room to talk in detail about this but the industry is full of idiots who insist that they were granted enough Professor X mindreading powers to be able to judge your character purely from your storytelling abilities so make up some fairy tales and rehearse them and you should be good to go. \n\nThat's it, \n\n\"Wait,\" I hear you say, \"That makes no sense. There's hardly anything here about building great software. What about real technical know-how? Having a history of being a good software craftsman? Doesn't that advance your career?\"\n\nNah bro. That's mostly for you. It's the reason why you're doing this and not some finance job. All the above bits just keep the paycheck healthy and the opportunities coming so that you can continue to enjoy writing good code and learning new things. Not the other way around. \n\nI've spent a long time in the industry watching people advance and not advance and learned much too late that it's the meta-game that moves your career forward, and moving the career forward is what benefits the technical game. Some of my peers understood this way early in their careers and now have much more comfortable lives than I will ever see. Hope this helps someone not make the same mistakes that I did.", "comment_Score": 1, "comment_Author": "dravacotron", "comment_Link_id": "1ccd1ep", "Create Date": "2024-04-25 07:20:16+00:00"}, {"comment_ID": "l161xw6", "comment_Body": "Yep signed up previously, but Medium wants me to get a paid subscription.", "comment_Score": 1, "comment_Author": "MachineParadox", "comment_Link_id": "1ccd6rs", "Create Date": "2024-04-25 07:12:24+00:00"}, {"comment_ID": "l161nlj", "comment_Body": "I think it\u2019s mostly Python tbh. Dbt for transform once you\u2019re in the db, but Python to do the extract/load.", "comment_Score": 1, "comment_Author": "nydasco", "comment_Link_id": "1cchtjk", "Create Date": "2024-04-25 07:09:04+00:00"}, {"comment_ID": "l160rm1", "comment_Body": "We haven't discussed a cloud migration yet, but it's a good point to consider.\n\nFor orchestration and storage we use just SQL because the guy doing it is pretty old-school. For analytics we use Power BI.\n\nDon't get me wrong in any way I'm just about to step foot into DE so if any of info provided by me doesn't add up, please do correct me.", "comment_Score": 1, "comment_Author": "Pillstyr", "comment_Link_id": "1cck5fd", "Create Date": "2024-04-25 06:58:58+00:00"}, {"comment_ID": "l160339", "comment_Body": "Data comparison tool that will work both with Snowflake and Sql server and Rds", "comment_Score": 1, "comment_Author": "awkward_period", "comment_Link_id": "1ccdveg", "Create Date": "2024-04-25 06:51:13+00:00"}, {"comment_ID": "l15ymat", "comment_Body": "I\u2019m very new to these tools. are these mainly available for free and not for enterprise (paid) services?", "comment_Score": 1, "comment_Author": "Frequent_Computer583", "comment_Link_id": "1ccd1ep", "Create Date": "2024-04-25 06:34:36+00:00"}, {"comment_ID": "l15x7zu", "comment_Body": "Excel as a Database? lol that sounds legit", "comment_Score": 2, "comment_Author": "Rude-Veterinarian-45", "comment_Link_id": "1ccdveg", "Create Date": "2024-04-25 06:19:09+00:00"}, {"comment_ID": "l15x22e", "comment_Body": "Understand customer purchase/spend behavior before your competition does it and gain advantage!", "comment_Score": 1, "comment_Author": "Rude-Veterinarian-45", "comment_Link_id": "1ccdveg", "Create Date": "2024-04-25 06:17:24+00:00"}, {"comment_ID": "l15wjsg", "comment_Body": "It\u2019s on Medium, so you may need a free account, but it\u2019s not paywalled.", "comment_Score": 0, "comment_Author": "nydasco", "comment_Link_id": "1ccd6rs", "Create Date": "2024-04-25 06:11:56+00:00"}, {"comment_ID": "l15wh3u", "comment_Body": "Shouldn\u2019t be. I get the option of whether to make it members only or not, and this isn\u2019t. It\u2019s free access. *may* require a free sign up. Not 100% sure on that. But definitely not paywalled.", "comment_Score": 0, "comment_Author": "nydasco", "comment_Link_id": "1ccd6rs", "Create Date": "2024-04-25 06:11:08+00:00"}, {"comment_ID": "l15w216", "comment_Body": "Snowflake is great, and their sales reps are sharks. It's probably a great place to work if you're in sales/marketing.", "comment_Score": 2, "comment_Author": "Sorel_CH", "comment_Link_id": "1cc9gh3", "Create Date": "2024-04-25 06:06:47+00:00"}, {"comment_ID": "l15vohq", "comment_Body": "Thank you for detail response!", "comment_Score": 2, "comment_Author": "sebastiandang", "comment_Link_id": "1ccian9", "Create Date": "2024-04-25 06:02:45+00:00"}, {"comment_ID": "l15viwn", "comment_Body": "I am surprised that business people know we exist. Most business user just want their dashboard, and they think it is just connected to the datasources directly.", "comment_Score": 1, "comment_Author": "kilodekilode", "comment_Link_id": "1cc9gh3", "Create Date": "2024-04-25 06:01:05+00:00"}, {"comment_ID": "l15v76b", "comment_Body": "Someone mentioned Kaggle as a tip for free datasets. I haven't tried it myself.\n\nMedallion architecture is all the rage as well, so you could try to find out good practices doing that on BigQuery.\n\nSetting up cost monitoring might be a nice one. Incremental ingestion and transformation would require some simulation, but is also very useful to learn about.", "comment_Score": 1, "comment_Author": "scataco", "comment_Link_id": "1ccfhl8", "Create Date": "2024-04-25 05:57:37+00:00"}, {"comment_ID": "l15v6b2", "comment_Body": "The amount of SAAS offerings that have \u2018we use AI and ML to improve your business\u2019 with no actual information on their LinkedIn account page is insane", "comment_Score": 1, "comment_Author": "ribrien", "comment_Link_id": "1ccdveg", "Create Date": "2024-04-25 05:57:21+00:00"}, {"comment_ID": "l15upnf", "comment_Body": "Sounds good technique and parquet is a good fit! \nHere are a few things to consider: \n\n1. If your log volume is very high, a low-spec application might struggle to keep up with the ingestion rate. \n2. Are you performing any transformations or filtering on the logs before storing them?\n3. How quickly do you need the logs to be available in the Bronze Layer?\n\nFor high-volume logs, consider streaming tools like Apache Kafka or Apache Flume!", "comment_Score": 2, "comment_Author": "Rude-Veterinarian-45", "comment_Link_id": "1ccian9", "Create Date": "2024-04-25 05:52:29+00:00"}, {"comment_ID": "l15unyn", "comment_Body": "Stick with code, if you can. That being said, where's your company migrating to? From on-prem oracle to... ? \n\nAlso, have a look at dbt, since you have an SQL background. That being said, realize that this is a multi-part question. How are you doing orchestration, storage, analytics, the E, L, and the T? \n\nFinally, ELT > ETL as far as I'm concerned.", "comment_Score": 2, "comment_Author": "SintPannekoek", "comment_Link_id": "1cck5fd", "Create Date": "2024-04-25 05:52:00+00:00"}, {"comment_ID": "l15undt", "comment_Body": "If they matter to you then what\u2019s stopping you using them for personal projects to learn them? \n\nNot using the fancy mainstream tools doesn\u2019t hurt your career because data engineers need to be generalists anyway. You should be able to learn them when needed.", "comment_Score": 1, "comment_Author": "YookiWH", "comment_Link_id": "1ccd1ep", "Create Date": "2024-04-25 05:51:50+00:00"}, {"comment_ID": "l15t1ch", "comment_Body": "Wasn't this basically Airtable?", "comment_Score": 1, "comment_Author": "lab-gone-wrong", "comment_Link_id": "1ccdveg", "Create Date": "2024-04-25 05:35:06+00:00"}, {"comment_ID": "l15sogg", "comment_Body": "If you focus on Pyspark and SQL with any dialect you will be able to pickup the majority of platform/tool-specifics within weeks if not days.  \n  \nFor Spark: pick up a bigger dataset off Kaggle (I use NFL Data Bowl to practice), use either a Databricks trial workspace or community edition, just load it in and try to do analytical stuff with it.  \n  \nFor SQL: the same, but try grabbing a Postgres or SQL Server version of the Adventureworks database. Can do it locally, in a Docker container, or in a cloud SQL instance. dbt can also be used here.  \n  \nYou will be shocked at how little time it takes to be useful with both. Your microservice background will be doubly as useful if you know the basics of the above.", "comment_Score": 5, "comment_Author": "mailed", "comment_Link_id": "1ccd1ep", "Create Date": "2024-04-25 05:31:25+00:00"}, {"comment_ID": "l15s5x0", "comment_Body": "\"you nerds\" said here, doesn't mean what it meant in the high school cafeteria in the US. I actually really appreciate the invitation to share our technical opinions.", "comment_Score": 2, "comment_Author": "MeditatingSheep", "comment_Link_id": "1cc9gh3", "Create Date": "2024-04-25 05:26:15+00:00"}, {"comment_ID": "l15s2o1", "comment_Body": "Is this via databricks? The log files will make sure they merge in the correct order. It is all done automatically, easy enough to test though to be sure.", "comment_Score": 1, "comment_Author": "Additional-Maize3980", "comment_Link_id": "1ccjshm", "Create Date": "2024-04-25 05:25:19+00:00"}, {"comment_ID": "l15rkte", "comment_Body": "We deliver data downloads that ranges from 35 MB to 6 GB to thousands of customers. Our formats are gzipped CSV, gzipped NDJSON and a special type of binary data format. This just works.", "comment_Score": 1, "comment_Author": "reincdr", "comment_Link_id": "1cbx8bb", "Create Date": "2024-04-25 05:20:24+00:00"}, {"comment_ID": "l15rkps", "comment_Body": "We are using ADF to copy the data into parquet, it always defaults the date", "comment_Score": 1, "comment_Author": "passing_marks", "comment_Link_id": "1cbx8bb", "Create Date": "2024-04-25 05:20:23+00:00"}, {"comment_ID": "l15rcmz", "comment_Body": "https://github.com/apache/parquet-format/blob/master/LogicalTypes.md#common-considerations\n\nUnless you are using nanosecond precision timestamps you shouldn\u2019t have any issue representing the year 1000 in parquet according to the spec. Nanoseconds for data that far back doesnt make sense anyway", "comment_Score": 2, "comment_Author": "exergy31", "comment_Link_id": "1cbx8bb", "Create Date": "2024-04-25 05:18:10+00:00"}, {"comment_ID": "l15qd7b", "comment_Body": "Please do! If it\u2019s good, I\u2019ll actually look into it for our stack.", "comment_Score": 1, "comment_Author": "JohnPaulDavyJones", "comment_Link_id": "1ccdveg", "Create Date": "2024-04-25 05:08:43+00:00"}, {"comment_ID": "l15prx1", "comment_Body": "Your post/comment was removed because it violated rule #3 (Do a search before asking a question). The question you asked has been answered in the wiki so we remove these questions to keep the feed digestable for everyone.", "comment_Score": 1, "comment_Author": "dataengineering-ModTeam", "comment_Link_id": "1cc6dnp", "Create Date": "2024-04-25 05:03:06+00:00"}, {"comment_ID": "l15papl", "comment_Body": "What library package are you using to send emails (e.g. imaplib)? Assuming the package sends an error code if the message fails, my suggestion would be to build a custom PTransform that takes in a PCollection of your email addresses and has two outputs, one for emails that succeed and one that fails after x number of retries. For outputs, create a key value pair where the key is some hardcode value like 1. In the next step you can do operations like combine by key if you wanted to get the total number of successful jobs or group and bulk uploads to BigQuery the failed jobs.\n\nOne things to note on your post. You won\u2019t be able to stream effectively if you are using BigQuery as your input as it is a bounded source. You maybe better off triggering batch jobs periodically and reading between the timestamp values.", "comment_Score": 1, "comment_Author": "sassypantsuu", "comment_Link_id": "1ccf7nm", "Create Date": "2024-04-25 04:58:36+00:00"}, {"comment_ID": "l15p9pr", "comment_Body": "Should I tell HR or the manager about this? Or just put my actual title (product safety specialist) on my background check and see if they comment on it?", "comment_Score": 1, "comment_Author": "seikoalpinist197", "comment_Link_id": "1ccf9zr", "Create Date": "2024-04-25 04:58:20+00:00"}, {"comment_ID": "l15p9br", "comment_Body": "This post was flagged as not being related enough to data engineering. In order to keep the quality and engagement high, we sometimes remove content that is unrelated or not relevant enough to data engineering.", "comment_Score": 1, "comment_Author": "dataengineering-ModTeam", "comment_Link_id": "1ccf9zr", "Create Date": "2024-04-25 04:58:14+00:00"}, {"comment_ID": "l15p7ws", "comment_Body": "Please see our rules about this topic in the sidebar.", "comment_Score": 1, "comment_Author": "dataengineering-ModTeam", "comment_Link_id": "1ccghx9", "Create Date": "2024-04-25 04:57:51+00:00"}, {"comment_ID": "l15p67f", "comment_Body": "This was true but five years back", "comment_Score": 1, "comment_Author": "king_booker", "comment_Link_id": "1ccdveg", "Create Date": "2024-04-25 04:57:24+00:00"}, {"comment_ID": "l15oe88", "comment_Body": "Iceberg supports parquet, orc and avro", "comment_Score": 1, "comment_Author": "madness_of_the_order", "comment_Link_id": "1cbx8bb", "Create Date": "2024-04-25 04:50:10+00:00"}, {"comment_ID": "l15odd6", "comment_Body": "Official company titles are not very important.   \nThe rule of thumb is to put your functional role as your title (as you have done) to make it clear what your role was, regardless what some \"creative\" person at your company deiced your title should be.\n\nThat said, \"Product Safety Specialist\" is a pretty strange title for someone doing analytics.\n\nIt is unlikely the background check will go that deep. If they do, they'll ask you about this (the recruiter or HM) and you can just explain that your day to day work was in analytics using x, y, z tool. But the company doesn't have an official \"Analytics Engineer\" role.\n\nI get why you are concerned but I wouldn't sweat this at all.", "comment_Score": 1, "comment_Author": "NoUsernames1eft", "comment_Link_id": "1ccf9zr", "Create Date": "2024-04-25 04:49:56+00:00"}, {"comment_ID": "l15n9ar", "comment_Body": "Well, here is my take. I have been a DE for close to 5 years now.\nEvery big org wants to move to the cloud but they don't realise how expensive the cloud is.\nFor starters I think having a way to manage cloud costs ( cloud provider agnostic) can be a good hit.\nThen if the solution can provide good cost saving recommendations then even better.", "comment_Score": 1, "comment_Author": "TheRedRoss96", "comment_Link_id": "1cc9gh3", "Create Date": "2024-04-25 04:39:39+00:00"}]