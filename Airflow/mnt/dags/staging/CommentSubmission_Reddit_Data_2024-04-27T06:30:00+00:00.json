[{"comment_ID": "l1gze59", "comment_Body": "i see, thanks", "comment_Score": 1, "comment_Author": "tablmxz", "comment_Link_id": "1cdqz5r", "Create Date": "2024-04-27 07:24:38+00:00"}, {"comment_ID": "l1gypq7", "comment_Body": "Full agreement. We recently migrated a >50-CTE-behemoth (a year old,  is going to be in production for some years to come) from Hive to Spark. It is so much easier to maintain, I am not looking back. That said, I still use a lot of SQL for simple and ad hoc queries.", "comment_Score": 1, "comment_Author": "perverse_sheaf", "comment_Link_id": "1cdjtn4", "Create Date": "2024-04-27 07:16:19+00:00"}, {"comment_ID": "l1gychr", "comment_Body": "I'm in devops looking to get into data engineering cuz i love working with data and i feel like it's more chill", "comment_Score": 1, "comment_Author": "z420a", "comment_Link_id": "1cdx354", "Create Date": "2024-04-27 07:11:50+00:00"}, {"comment_ID": "l1gy8kb", "comment_Body": "My leader the same, everything done via python libraries.\n\nI spend 10 times longer forking about writing python than just writing the forking sql.\n\nI think it\u2019s insane but I\u2019m not in charge so as long as I get paid I don\u2019t care anymore as have copped shit for debating it in the past", "comment_Score": 1, "comment_Author": "Ok_Relative_2291", "comment_Link_id": "1cdjtn4", "Create Date": "2024-04-27 07:10:31+00:00"}, {"comment_ID": "l1gxh5r", "comment_Body": ">It's just draining for me to connect with new people as an introvert and i don't want to look desperate for a job only my work and projects talks for me\u00a0\n\nI too felt the same few months ago, but I forced myself to better my social skills(not just in professional but all ways), and connected with as many people as I can and saw how I could help them in both professional and personal space. And it is working for me, getting new friends, getting interviews scheduled and many more. \n\nDon't ever believe your work will talk for you, it will do the talking but you have to start the conversation first.", "comment_Score": 1, "comment_Author": "iamthatmadman", "comment_Link_id": "1cds5yo", "Create Date": "2024-04-27 07:01:23+00:00"}, {"comment_ID": "l1gwt28", "comment_Body": "They must have a lot of money. Best case they use each tool only for the part they are best at.\n\nWorst case, it's a mixed architecture by use case / department / team.", "comment_Score": 1, "comment_Author": "tzt1324", "comment_Link_id": "1ce7ly4", "Create Date": "2024-04-27 06:53:30+00:00"}, {"comment_ID": "l1gwihm", "comment_Body": "I know all that in theory - I understand the function of these services, but I feel I lack a deep understanding how networking/ sec work.", "comment_Score": 1, "comment_Author": "user2401372", "comment_Link_id": "1cdgi6u", "Create Date": "2024-04-27 06:50:03+00:00"}, {"comment_ID": "l1gwafm", "comment_Body": "Hey stranger glad to connect just DM me", "comment_Score": 1, "comment_Author": "Thinker_Assignment", "comment_Link_id": "1cds5yo", "Create Date": "2024-04-27 06:47:25+00:00"}, {"comment_ID": "l1gw5pe", "comment_Body": "What are the typical queries (access patterns) planned in the system ?", "comment_Score": 1, "comment_Author": "rasviz", "comment_Link_id": "1ccoerb", "Create Date": "2024-04-27 06:45:51+00:00"}, {"comment_ID": "l1gvyeh", "comment_Body": "Definitely interested in the data you sell", "comment_Score": 1, "comment_Author": "freebird348", "comment_Link_id": "1ce0ohq", "Create Date": "2024-04-27 06:43:28+00:00"}, {"comment_ID": "l1gvk50", "comment_Body": "I would day it depends on the size of data.  If your scheduled jobs data size  wont grow and hover less than 1 GB or so  Airflow might be able to do it with in its task itself. If the size of data to be processed is growing exponentially or if its massive, use any big data processing engine and use airflow to orchestrate it. Like Spark or flink. Sharing data between tasks should be generally by the storage layer like S3 or GCS. Xcom is not designed to transfer the data itself. You can exchange the location of data (S3 path) through xcom. There is a way to map xcom to S3, its in a config  called xcom\\_backend. I will not explore it at this stage.", "comment_Score": 1, "comment_Author": "mortal-psychic", "comment_Link_id": "1cc0mqb", "Create Date": "2024-04-27 06:38:38+00:00"}, {"comment_ID": "l1gvjkj", "comment_Body": "We had a consultancy firm come in to help with reducing costs and it cut our bill in half.  \nI am worried about the enshittification phase in a few years, though.", "comment_Score": 1, "comment_Author": "dessmond", "comment_Link_id": "1ce0ohq", "Create Date": "2024-04-27 06:38:27+00:00"}, {"comment_ID": "l1gvj5a", "comment_Body": "Jesus,  I feel for you, man. I haven't handled replication with SAP. I mostly set up data pipelines in Power Bi with the on-prem gateway and .NET connector. The worst part of SAP is the decentralized nature of products they offer. Working in a large corporate environment, there are many issues that show up around access control and roles. It took me 2-3 months just to get a GAC driver installed, to then get the SAP connector to work. When it was finally set up, I found I could only connect to pre-written Bex queries. When I asked where to find the master data, I had to download all the designer apps only to get denied write access for query designer. Now, if I need data from BW, I have to load all of the pre-written queries and comb through them to see if there is a dataset broad enough to work. \n\nFront end and back end UX is hot garbage!", "comment_Score": 1, "comment_Author": "kkessler1023", "comment_Link_id": "1ccv2r3", "Create Date": "2024-04-27 06:38:19+00:00"}, {"comment_ID": "l1guswc", "comment_Body": "You say you have 50TB now, but to how far must it scale? And how fast is your internet service, down and up? 400mbit UP will allow you to upload 144 GB per hour. If you are working on 2 projects and deltas run into TBs the upload will take 10 to 30 hours.", "comment_Score": 1, "comment_Author": "dessmond", "comment_Link_id": "1cdvxow", "Create Date": "2024-04-27 06:29:52+00:00"}, {"comment_ID": "l1guil5", "comment_Body": "Well, IMHO the modelling (DS or analytics for that matter) is where the magic happens... So it's rarely a case of just using tools, else we wouldn't provide any value as data teams (I mean if that's the case: just use the tools, right?)\n\nAnd that's kind of the whole point of what I was saying with \"fullstack data engineering\" => in such a role you're not \"just\" technical. You also have to get to understand the business needs and hence how you might go about it from the data (available or not...), and only then you get into the technical reflexion on how to actually do it.", "comment_Score": 1, "comment_Author": "briceluu", "comment_Link_id": "1ccsf39", "Create Date": "2024-04-27 06:26:30+00:00"}, {"comment_ID": "l1gtpgb", "comment_Body": "Hi\n\n3NF is just a common term used to describe the design methods for OLTP systems.  As a general practice, 3NF is the way most OLTPs are designed (but you can go to higher in normalization).  \n\nA classical dimensional model (each dimension is a single table) is more like 1NF.   However, if you design a dimensional model and incorporate snowflaking you can end up with a 3NF design which is dimensional.", "comment_Score": 1, "comment_Author": "GreyHairedDWGuy", "comment_Link_id": "1cdrhdu", "Create Date": "2024-04-27 06:17:06+00:00"}, {"comment_ID": "l1gtdqk", "comment_Body": "Could you also dm me please", "comment_Score": 1, "comment_Author": "WallResponsible9918", "comment_Link_id": "1b4r198", "Create Date": "2024-04-27 06:13:28+00:00"}, {"comment_ID": "l1gs55z", "comment_Body": "Yeah, if I get a message explaining why they want to connect I might accept. If you ask some questions I normally take the time to answer them, and converse. Maybe a couple times a year I converse with strangers who are figuring out how to get started, but I never accept invites from strangers with nothing in common if they don\u2019t explain why.", "comment_Score": 2, "comment_Author": "dr_craptastic", "comment_Link_id": "1cds5yo", "Create Date": "2024-04-27 05:59:53+00:00"}, {"comment_ID": "l1grqq0", "comment_Body": "RAID is \"Redundant Array of Independent Disks\". It can be either a hardware (RAID controller) or software level configuration. You basically take multiple drives, depending on the RAID level you're using, and the hardware or software divvies up the drives as needed to support the RAID level you've assigned. For instance, RAID 1 is mirroring, which means when you write to a logical volume, you're actually writing it in two physical locations. Your RAID configuration actually handles the mirroring, so you only see one location, but in the background, everything is mirrored on both logical volumes. One drive goes down, you still have a access to everything because of the mirrored volume. But that also means you halve your total storage. This is the most basic level of fault tolerance, and you should aim for a more complete solution like RAID 5 or 6 or 10.\n\nS3 costs are in egress and time. Something stored in glacier is going to be cheaper to just sit there than in standard storage, but if you need access to the file, it will take time to \"thaw\" and make it available. And AWS charges you for network egress (data leaving AWS) to pull it down from S3. 1-2 TB/mo of egress from S3 will cost between $100 and $200 per month.\n\nYour best bet might be looking at one of those cloud storage providers like Backblaze or pics.io. They still use public cloud storage, but larger entities usually get discounts from cloud providers for their business, so they might give you \"Unlimited\" options that are more affordable, but still profitable for them. I would reach out to a few of them directly and ask them about your specific use case and get certain things in writing. Most of them have \"Fair Usage\" guidelines that do put some practical limits on ingress and egress or file sizes or might throttle transfers above a certain amount. So be very explicit about your needs and make sure you read all the fine print.", "comment_Score": 1, "comment_Author": "BuildingViz", "comment_Link_id": "1cdvxow", "Create Date": "2024-04-27 05:55:35+00:00"}, {"comment_ID": "l1gr7ih", "comment_Body": "What kind of data do you sell?", "comment_Score": 2, "comment_Author": "Martekk_", "comment_Link_id": "1ce0ohq", "Create Date": "2024-04-27 05:49:51+00:00"}, {"comment_ID": "l1gqtbz", "comment_Body": "\"personally identifiable information\", to avoid problems with the General Data Protection Regulation - GDPR", "comment_Score": 3, "comment_Author": "Kaze_Senshi", "comment_Link_id": "1ce0ohq", "Create Date": "2024-04-27 05:45:43+00:00"}, {"comment_ID": "l1goqhc", "comment_Body": "for the rest of us mere mortals though... ;)", "comment_Score": 1, "comment_Author": "mailed", "comment_Link_id": "1cdjtn4", "Create Date": "2024-04-27 05:24:07+00:00"}, {"comment_ID": "l1goeev", "comment_Body": "People always fight for the stack they\u2019re most comfortable with and have a background in. It honestly has nothing to do with SQL or Scala or Rust or whatever. The only thing that matters is getting the right data and quality data for data science, analytics and BI.\n\nUnfortunately in this situation, it looks like your coworker had more influence and he won. This is not an uncommon scenario. In my previous job, a senior engineer who had more of a backend engineering background came to our DE team and completely revamped the entire code base that we had written in PySpark into Scala Spark because HE liked functional languages. He was at the company for 25 years and management didn\u2019t question him. So we had to learn Scala. SMH!!", "comment_Score": 1, "comment_Author": "MotherCharacter8778", "comment_Link_id": "1cdjtn4", "Create Date": "2024-04-27 05:20:49+00:00"}, {"comment_ID": "l1gn1nq", "comment_Body": "Agreed", "comment_Score": 1, "comment_Author": "soundboyselecta", "comment_Link_id": "1cdjtn4", "Create Date": "2024-04-27 05:07:27+00:00"}, {"comment_ID": "l1gn148", "comment_Body": "How did you cold call/message people? What was your strategy? I can shoot the shit with anyone but haven't found the best way to get peoplw on the phone/conversing regularly on linkedin", "comment_Score": 2, "comment_Author": "johnsonfrusciante", "comment_Link_id": "1cds5yo", "Create Date": "2024-04-27 05:07:17+00:00"}, {"comment_ID": "l1gmlcv", "comment_Body": "I believe that is build off their data share technology. That shit is lightning fast. I leverage a transactional platform where we purchase media in real time, and I can see my campaign data via a Snowflake AWS datashare in as little as 10 minutes whereas the platforms themselves take hours to update with aggregate indicators. I\u2019ve built dashboards off of this data to QA our buys faster than we could natively in the companies own software.\n\nIt requires almost 0 ETL, just tell SF where to point the table and query away", "comment_Score": 9, "comment_Author": "JimmyTango", "comment_Link_id": "1ce0ohq", "Create Date": "2024-04-27 05:02:59+00:00"}, {"comment_ID": "l1gmf4m", "comment_Body": "They have some differences, but they\u2019re mostly comparable. Some people just don\u2019t want to be on GCP, and Snowflake will deploy anywhere.", "comment_Score": 6, "comment_Author": "thrav", "comment_Link_id": "1ce0ohq", "Create Date": "2024-04-27 05:01:18+00:00"}, {"comment_ID": "l1glk7b", "comment_Body": "This rings true for me. They've got a winning combo for extracting maximum cash from clients:\n\n1. Ready to go solution that cuts down on the number of pesky employees you have to depend on\n2. Cleverly obfuscated pricing that \\*looks\\* like you know what it's going to cost you, when actually you've no idea what the bill is going to be from one month to the next", "comment_Score": 2, "comment_Author": "bree_dev", "comment_Link_id": "1ce0ohq", "Create Date": "2024-04-27 04:53:11+00:00"}, {"comment_ID": "l1glfks", "comment_Body": "Other on-prem versions are even costlier with less performance.", "comment_Score": 0, "comment_Author": "VolTa1987", "comment_Link_id": "1ce0ohq", "Create Date": "2024-04-27 04:51:58+00:00"}, {"comment_ID": "l1gkfw6", "comment_Body": "I'm just starting to work with spark,  but this guy sounds like a pretentious twat. Is he suggesting to eliminate sql from any part of the ingestion process? It seems like a good way to over complicate things.", "comment_Score": 1, "comment_Author": "kkessler1023", "comment_Link_id": "1cdjtn4", "Create Date": "2024-04-27 04:42:50+00:00"}, {"comment_ID": "l1gjksw", "comment_Body": "Management didn't know SQL from shell scripting. IT has always been managed by people who don't understand it.", "comment_Score": 2, "comment_Author": "BarrySix", "comment_Link_id": "1cdjtn4", "Create Date": "2024-04-27 04:34:57+00:00"}, {"comment_ID": "l1gj8v9", "comment_Body": "Thank you. That is great info", "comment_Score": 2, "comment_Author": "Normal-Inspector7866", "comment_Link_id": "1ce0ohq", "Create Date": "2024-04-27 04:31:55+00:00"}, {"comment_ID": "l1giuqk", "comment_Body": "It\u2019s almost always because of three things:\n\n1) Poor data architecture without separation of concerns, eg like letting people query raw data directly. \n\n2) an unnecessarily large amount of transformations and models (I\u2019m looking at you, dbt)\n\n3) Poor SQL syntax because people don\u2019t understand columnar storage of data warehouses.\n\nSnowflake works just fine and with the right set up will be fast and efficient. But it\u2019s also very forgiving and will just throw compute at the three issues above so that your bill will just keep racking up. \n\nSo get a data engineer who understands setting up Snowflake correctly, set guardrails for your transformation layer and teach your analysts good SQL.", "comment_Score": 1, "comment_Author": "Current_Doubt_8584", "comment_Link_id": "1ce0ohq", "Create Date": "2024-04-27 04:28:25+00:00"}, {"comment_ID": "l1gikj3", "comment_Body": "You can limit that with a warehouse and resource monitor\u00a0", "comment_Score": 3, "comment_Author": "Fantastic-Schedule15", "comment_Link_id": "1ce0ohq", "Create Date": "2024-04-27 04:25:51+00:00"}, {"comment_ID": "l1ghwnm", "comment_Body": "Not weird at all. I run a consulting firm, which has a data and IA verticle. I get heaps of randos sending me requests, I accept all of them (unless I can smell some kinda scam). \n\nI've since given advise to people all over the world, all walks of life and all ages. But they all share a common love of working with data, that I can tell.", "comment_Score": 1, "comment_Author": "Additional-Maize3980", "comment_Link_id": "1cds5yo", "Create Date": "2024-04-27 04:19:56+00:00"}, {"comment_ID": "l1ghgdq", "comment_Body": "I haven't done that, but it should work. It's a straightforward process:\n\n* Add the CSV to the seeds\n* Reference the seed model as you would the SQL model", "comment_Score": 1, "comment_Author": "ivanovyordan", "comment_Link_id": "198w13u", "Create Date": "2024-04-27 04:16:01+00:00"}, {"comment_ID": "l1gge2b", "comment_Body": "Cheaper than GBQ. But I don\u2019t like it as much\u2026", "comment_Score": 2, "comment_Author": "UnrealizedLosses", "comment_Link_id": "1ce0ohq", "Create Date": "2024-04-27 04:06:24+00:00"}, {"comment_ID": "l1gg95m", "comment_Body": "Depends on where you are starting from", "comment_Score": 1, "comment_Author": "deemerritt", "comment_Link_id": "1ce0ohq", "Create Date": "2024-04-27 04:05:12+00:00"}, {"comment_ID": "l1gg7vw", "comment_Body": "Wow TIL.", "comment_Score": 8, "comment_Author": "icysandstone", "comment_Link_id": "1ce0ohq", "Create Date": "2024-04-27 04:04:52+00:00"}, {"comment_ID": "l1gg2t5", "comment_Body": "You mean like no star schema? All 3NF?", "comment_Score": 2, "comment_Author": "icysandstone", "comment_Link_id": "1ce0ohq", "Create Date": "2024-04-27 04:03:39+00:00"}]