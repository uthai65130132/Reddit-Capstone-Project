[{"comment_ID": "l1cbvnv", "comment_Body": "Spark definitely does both of those things! Resource manager handles auto scaling, though there are better implementations on Databricks or other managed services. Spark operates with partitions well in mind, and as of 3.0 does automatic even distribution of data across machines and on write depending on format. \n\nOptimized autoscaling on Databricks back in 2018: https://www.databricks.com/blog/2018/05/02/introducing-databricks-optimized-auto-scaling.html\n\nYou can also scale with spark on Kubernetes quite easily.", "comment_Score": 1, "comment_Author": "Blayzovich", "comment_Link_id": "1cdg89d", "Create Date": "2024-04-26 12:28:17+00:00"}, {"comment_ID": "l1cbo5g", "comment_Body": "In that case, does one look for a new job or just stay and milk it? OP says the job market is shit still.", "comment_Score": 1, "comment_Author": "paxmlank", "comment_Link_id": "1cdjtn4", "Create Date": "2024-04-26 12:26:46+00:00"}, {"comment_ID": "l1cbcbl", "comment_Body": "Any DE who says SQL has no place in the DE world will be out of a job in 5 years.\n\nHonestly ur leadership is shit if they follow such dumb statements", "comment_Score": 1, "comment_Author": "Hackerjurassicpark", "comment_Link_id": "1cdjtn4", "Create Date": "2024-04-26 12:24:24+00:00"}, {"comment_ID": "l1cawqs", "comment_Body": "Has anyone had experience with [Equals](https://equals.com)? \n\nTheir marketing speak is if excel was built today.", "comment_Score": 1, "comment_Author": "miqcie", "comment_Link_id": "1b04b8j", "Create Date": "2024-04-26 12:21:13+00:00"}, {"comment_ID": "l1cawqe", "comment_Body": "From what I've seen it's a tradeoff between platform costs and developer costs. Snowflake platform could be more expensive but a generic analyst with some basic upskilling could build on it. While spark requires hiring specialized engineering talent. So it depends on which the company wants to prioritize", "comment_Score": 1, "comment_Author": "Hackerjurassicpark", "comment_Link_id": "1cdg89d", "Create Date": "2024-04-26 12:21:13+00:00"}, {"comment_ID": "l1caonv", "comment_Body": "Definitely! I have used Airbyte regularly (self-hosted) for the last couple of years, and it has been great so far. Airbyte is a fantastic addition to this stack.\n\nOverall, I think what makes for a good stack is a small collection of reliable, single-purpose components (e.g. orchestration: Dagster, integration: Airbyte, transformation: dbt, SQL warehouse: Postgres), where the following criteria hold true:\n* each component can be replaced or upgraded\n* the components are designed to work together\n* more components can be added (as needed)\n\n\nOn a side note: I think working as a solo DE at a young, enthusiastic company is a fantastic way to test one's chops at data engineering (not to mention exciting!). High impact data projects in a limited resource environment are a great way to get a *ton* of experience, wear a lot of hats, interact with great people, and prove your worth \u2014 both to the company and to yourself.", "comment_Score": 1, "comment_Author": "Separate_Newt7313", "comment_Link_id": "1ccs3vs", "Create Date": "2024-04-26 12:19:34+00:00"}, {"comment_ID": "l1cafjc", "comment_Body": "I went through this last year. Hundreds of applications and probably >90% auto-rejected. This was in the midst of the big layoff spree, last spring. Ended up with 2 offers. The one I accepted came from a recruiter who initiated contact, and had found me through some AI job search he uses. Zero success on any job sites or applications of any kind. It took about 3 months to get hired.", "comment_Score": 1, "comment_Author": "zambizzi", "comment_Link_id": "1camjik", "Create Date": "2024-04-26 12:17:43+00:00"}, {"comment_ID": "l1ca9uc", "comment_Body": "Yes and no, \nWith DH OS i get a head start", "comment_Score": 1, "comment_Author": "InsightByte", "comment_Link_id": "1cd8xbl", "Create Date": "2024-04-26 12:16:32+00:00"}, {"comment_ID": "l1ca8ob", "comment_Body": "People don\u2019t like them because of their aggressive marketing strategy using annoying LinkedIn influencers like Zach Wilson (who they bring on as \u201cadvisors\u201d). That, plus they faked their GitHub star count.", "comment_Score": 1, "comment_Author": "shmorkin3", "comment_Link_id": "1cda190", "Create Date": "2024-04-26 12:16:18+00:00"}, {"comment_ID": "l1ca3fd", "comment_Body": "if the product is so bad how can you say it\u2019s one of the best ERPs in the world?", "comment_Score": 1, "comment_Author": "yo_sup_dude", "comment_Link_id": "1ccv2r3", "Create Date": "2024-04-26 12:15:11+00:00"}, {"comment_ID": "l1c9jim", "comment_Body": "Fuck - Snowflake\n\nMarry - BigQuery\n\nKill - Redshift\n\nBefriend - Databricks", "comment_Score": 1, "comment_Author": "Kobosil", "comment_Link_id": "1cdjiby", "Create Date": "2024-04-26 12:11:02+00:00"}, {"comment_ID": "l1c97we", "comment_Body": "I disagree with what others are saying. If you\u2019re responsible for loading source data for a company, you will most definitely be on call. If something goes wrong at night during a batch cycle, you will most definitely be woken up", "comment_Score": 1, "comment_Author": "NoConstruction9902", "comment_Link_id": "1cd6v3c", "Create Date": "2024-04-26 12:08:35+00:00"}, {"comment_ID": "l1c953b", "comment_Body": "CustomerName is dependent on CustomerId which is a part of primary key. So there is partial dependency, which violates 2NF. Therefore, the table is 1NF at best.", "comment_Score": 1, "comment_Author": "de_enthusiast", "comment_Link_id": "1cb573s", "Create Date": "2024-04-26 12:07:59+00:00"}, {"comment_ID": "l1c8cgj", "comment_Body": "Learn express route, VNet, NSG, private link/private endpoints.\n\nMS learn is a good resource, but utilising Azure credits to set up a real env is even better.", "comment_Score": 1, "comment_Author": "MachineParadox", "comment_Link_id": "1cdgi6u", "Create Date": "2024-04-26 12:01:50+00:00"}, {"comment_ID": "l1c8apk", "comment_Body": "create a databricks community edition account. You can create clusters, use DBFS and pyspark", "comment_Score": 1, "comment_Author": "NoConstruction9902", "comment_Link_id": "1cd15m2", "Create Date": "2024-04-26 12:01:27+00:00"}, {"comment_ID": "l1c7j36", "comment_Body": "Would\nSelect cols from {cte you want} do what you want?", "comment_Score": 1, "comment_Author": "gffyhgffh45655", "comment_Link_id": "1cdha2w", "Create Date": "2024-04-26 11:55:27+00:00"}, {"comment_ID": "l1c71mm", "comment_Body": "+1. Parsing JSON is the only use case for writing recursive functions I've had in my professional programming career.", "comment_Score": 1, "comment_Author": "ambidextrousalpaca", "comment_Link_id": "1ccsms9", "Create Date": "2024-04-26 11:51:38+00:00"}, {"comment_ID": "l1c6kt7", "comment_Body": "I thought spark doesn't assist in any way with auto scaling and partitioning? Except for the GUI stuff isn't that kinda what  snowflake etc have on it? Basically everything is possible but you need to say you want it.", "comment_Score": 1, "comment_Author": "MrGraveyards", "comment_Link_id": "1cdg89d", "Create Date": "2024-04-26 11:47:54+00:00"}, {"comment_ID": "l1c6eoh", "comment_Body": "It\u2019s been growing on me", "comment_Score": 1, "comment_Author": "Lilab0001", "comment_Link_id": "1cdg89d", "Create Date": "2024-04-26 11:46:32+00:00"}, {"comment_ID": "l1c6a0r", "comment_Body": "High performance Python is Python that wraps C/C++/Fortran code and is really quick. Python is huge in machine learning because it is a wrapper around C/C++ code for calling CUDA.\n\nIn this stackoverflow thread Scala Spark is slower then PySpark: [https://stackoverflow.com/questions/32464122/spark-performance-for-scala-vs-python](https://stackoverflow.com/questions/32464122/spark-performance-for-scala-vs-python)\n\nMaybe because the author doesn't know how to get the best out of Scala but still, PySpark is not regular native Python that is indeed slow.", "comment_Score": 1, "comment_Author": "j0holo", "comment_Link_id": "1cdg89d", "Create Date": "2024-04-26 11:45:31+00:00"}, {"comment_ID": "l1c671c", "comment_Body": "That's boring? Nothing more exciting than a thing that just works and happy customers I say", "comment_Score": 3, "comment_Author": "InternetAnima", "comment_Link_id": "1cdg89d", "Create Date": "2024-04-26 11:44:52+00:00"}, {"comment_ID": "l1c63mb", "comment_Body": "I have a repo that can help: https://github.com/josephmachado/efficient_data_processing_spark/tree/main\n\nIt has Pyspark + Jupyter + Delta + Minio (S3 oss) and TPCH data \n\nLMK if you have any questions :)", "comment_Score": 1, "comment_Author": "joseph_machado", "comment_Link_id": "1cd15m2", "Create Date": "2024-04-26 11:44:07+00:00"}, {"comment_ID": "l1c5jok", "comment_Body": "No, sorry, even if I had it I wouldn\u2019t feel comfortable. But there was really nothing to it:\n1. Query some sample data and save as orc with pyarrow\n2. Save to s3 and create new external table in Redshift\n3. Query each table in exponentially increasing subsets (the 5k, 50k, etc), benchmarking with the `%%timeit` magic in Jupyter \n4. Visualize the benchmark results (using log scale on the num rows scale)", "comment_Score": 1, "comment_Author": "EarthGoddessDude", "comment_Link_id": "1cbx8bb", "Create Date": "2024-04-26 11:39:36+00:00"}, {"comment_ID": "l1c4w2q", "comment_Body": "From what I've seen in industry, most MPP technologies seem to be far more expensive as they scale compared to Spark (even managed). Have you seen something similar?\n\nAlso, Spark does streaming so it handles those sets of use-cases too.", "comment_Score": 2, "comment_Author": "Blayzovich", "comment_Link_id": "1cdg89d", "Create Date": "2024-04-26 11:34:14+00:00"}, {"comment_ID": "l1c4lqp", "comment_Body": "Look at the title and the list, nowhere does it say this is based on opinion. It's rather annoying to professionals such as myself on reddits like these that are full of absolute garbage and I'm just calling that out, if you want to present an opinion go for it but at least state it first.\n\nIt's the same with medium articles in the last few years, full of people writing garbage just to pat themselves on the back without actually contributing anything.", "comment_Score": 1, "comment_Author": "Ok_Raspberry5383", "comment_Link_id": "1ccodiy", "Create Date": "2024-04-26 11:31:54+00:00"}, {"comment_ID": "l1c450d", "comment_Body": "I think you are asking in the wrong sub - if your alternative is dask jobs and you are talking about high performance cpp and python. I would suggest r/HPC ?\n\n  \nspark was designed for massively parallel 'simple' processing on enormous datasets. rather than high performance clusters which I think is what you are after", "comment_Score": 1, "comment_Author": "seanv507", "comment_Link_id": "1cdg89d", "Create Date": "2024-04-26 11:28:01+00:00"}, {"comment_ID": "l1c3odn", "comment_Body": "exactly. if you didn't need it before you certainly don't need it now. It's certainly not a 'boring technology'", "comment_Score": 1, "comment_Author": "seanv507", "comment_Link_id": "1cdg89d", "Create Date": "2024-04-26 11:24:10+00:00"}, {"comment_ID": "l1c2je0", "comment_Body": "I have noticed that mentioning mage gets you down votes around here. I'm using mage and I think for my use case it's appropriate.  \n\nMage has some deficiencies but overall the experience has been good. \n\nMy 2 major concerns are \n\n1. It is slow but Mage has said they are prioritizing speed this year. \n\n2. Will it continue to be open source. It's VC funded and eventually they will want to monetize.", "comment_Score": 2, "comment_Author": "wannabe-DE", "comment_Link_id": "1cda190", "Create Date": "2024-04-26 11:14:16+00:00"}, {"comment_ID": "l1c2hvm", "comment_Body": "That's excellent! A great way to automate simple stuff then instead of paying AWS or running locally", "comment_Score": 1, "comment_Author": "Comfortable_Spread", "comment_Link_id": "1cd0tmv", "Create Date": "2024-04-26 11:13:54+00:00"}, {"comment_ID": "l1c2f9a", "comment_Body": "AI can't make that job for you. It is exactly the opposite of making consious effort. Connection between business process and data repressing it is outside of scope information given to AI engin, it has no connection to real physical world.", "comment_Score": 1, "comment_Author": "baubleglue", "comment_Link_id": "1ccdveg", "Create Date": "2024-04-26 11:13:14+00:00"}, {"comment_ID": "l1c1y8g", "comment_Body": "Well, It depends on your perspective and the scale of your data. Spark does its job well and indeed a powerful tool in the data batch/micro batch processing game. The main advantage is its open source. May be try joining your data sets using  high-performance CPP, Python and spark to know the difference!\n\nHowever, if your data requirements are more modest, Dask is certainly worth considering as well.", "comment_Score": 2, "comment_Author": "Rude-Veterinarian-45", "comment_Link_id": "1cdg89d", "Create Date": "2024-04-26 11:08:58+00:00"}, {"comment_ID": "l1c1t87", "comment_Body": "I understand high performance cpp.\n\nWTF is high performance python \ud83d\ude2c. Python is good enough for scripting and hobby projects.\n\nIf you\u2019re looking for true high performance and true object oriented language option for Spark, look at Scala.\n\nSorry to hurt the Python fan\u2019s feelings.\n\nComing back to Spark being boring, to have challenging tasks try work on performance optimization on shared on-Prem clusters(most of the early adopters of big data are still on prem).", "comment_Score": -2, "comment_Author": "RevolutionaryBid2619", "comment_Link_id": "1cdg89d", "Create Date": "2024-04-26 11:07:41+00:00"}, {"comment_ID": "l1c1fjb", "comment_Body": "You didn't need a chart to see the massive uptick in useless influencers. We're headed for the same fate as data science and data warehousing. That was the theme of my talk at Data Day Texas.", "comment_Score": 1, "comment_Author": "eljefe6a", "comment_Link_id": "1ccsf39", "Create Date": "2024-04-26 11:04:10+00:00"}, {"comment_ID": "l1c1bft", "comment_Body": "GitHub owns the computer here. On private repos you get X free minutes a month. On public repos you get unlimited amounts of minutes a month.", "comment_Score": 2, "comment_Author": "Luxi36", "comment_Link_id": "1cd0tmv", "Create Date": "2024-04-26 11:03:05+00:00"}, {"comment_ID": "l1c1707", "comment_Body": "Not the only, you'll find exceptions, but that's generally the flow.", "comment_Score": 1, "comment_Author": "Thin_Platform5774", "comment_Link_id": "1cdfiow", "Create Date": "2024-04-26 11:01:56+00:00"}, {"comment_ID": "l1c0zgz", "comment_Body": "I find this a really interesting take and a way of thinking i haven't tried before so I will bite.\nI am currently a data engineer atn a group level  dataplatform of an international company. Every day we ingest hundreds of tables for multiple sources.\n\nWe use an orchestrator to every night do a batch load. So every night a main pipeline is started which then gets some metadata about the tables to be loaded. For every table the right type of sub pipeline is triggered which ingests and processes the data.\n\nIf that's done the data is loaded into data models after which the refreshes of PowerBI reports based on those datasets is triggered.\n\nHow would you go about this without an orchestrator?", "comment_Score": 1, "comment_Author": "blindbox2", "comment_Link_id": "1cda190", "Create Date": "2024-04-26 10:59:59+00:00"}, {"comment_ID": "l1bzyc4", "comment_Body": "Spark is great if your on Prem or on Databricks. But I'm seeing lesser and lesser folk using it as snowflake/big query becomes more popular", "comment_Score": 2, "comment_Author": "Hackerjurassicpark", "comment_Link_id": "1cdg89d", "Create Date": "2024-04-26 10:50:10+00:00"}, {"comment_ID": "l1bzjdc", "comment_Body": "I don't understand what you mean, just like all statistical lists, everyone will discuss the list and give their own opinions, no one will say that the list itself is a fact, and the person who sent the list will not be wrong.", "comment_Score": 0, "comment_Author": "Gezi-lzq", "comment_Link_id": "1ccodiy", "Create Date": "2024-04-26 10:46:07+00:00"}, {"comment_ID": "l1byn5s", "comment_Body": "jsonl .", "comment_Score": 1, "comment_Author": "Stick-Spiritual", "comment_Link_id": "1ccsms9", "Create Date": "2024-04-26 10:37:18+00:00"}, {"comment_ID": "l1byauj", "comment_Body": "That will just make the jobs market more competitive lol.", "comment_Score": 1, "comment_Author": "icest0", "comment_Link_id": "1ccsf39", "Create Date": "2024-04-26 10:33:48+00:00"}]