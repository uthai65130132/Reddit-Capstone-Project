[{"submission_ID": "1cbrdoa", "submission_Title": "Best Data Engineering Books?", "submission_Score": 6, "submission_Author": "ResidentMaize2535", "submission_selftext": "Best data engineering books that are current. Audio if possible. ", "Create Date": "2024-04-24 06:28:40+00:00"}, {"submission_ID": "1cbqz2j", "submission_Title": "Personal Project", "submission_Score": 2, "submission_Author": "happyplantt", "submission_selftext": "I\u2019m graduating in 3 weeks, I am thinking of this random thing to showcase on my GitHub. My idea is to implement remote gas stations (Like a fuel truck). The plan is to get the traffic dataset of an area and analyze the data for all days of the week. Create a heatmap and then plot the existing gas stations on the map. Now the goal is to select top 5 places where there is traffic and less gas stations. (Assuming gas stations are required at high traffic flow areas).\nI\u2019m not sure where to start, I mean where can I get the datasets other than kaggle. And also can someone help me to brainstorm the things I need to focus on. Thanks", "Create Date": "2024-04-24 06:01:45+00:00"}, {"submission_ID": "1cbq7ga", "submission_Title": "H\u01a1w to design basic relational models for a regularly banking system?", "submission_Score": 3, "submission_Author": "SonixNgTbr", "submission_selftext": "I have a task relating to banking but I am not related to the financial industry. Get stuck in designing model relationships and which basic, required tables should have? Thank you", "Create Date": "2024-04-24 05:14:36+00:00"}, {"submission_ID": "1cbq5ys", "submission_Title": "Advice Needed To Move Jobs", "submission_Score": 2, "submission_Author": "Prestigious-Carob715", "submission_selftext": "Hello everyone,\nI hope you\u2019re all having a splendid day. I just wanted to ask for some advice to overcome my current situation. So I have been working as a data engineer for a company in India from the US. Needless to say the pay, benefits, work life balance are terrible so I am looking into switching jobs. I have only 1.5 yrs of experience as I am a recent graduate 2023. I was just wondering if anyone has ever been in the same situation and was able to find a job. Thank you so much. I truly appreciate it. I will try to answer any questions about my background in the comments as soon as possible.", "Create Date": "2024-04-24 05:12:05+00:00"}, {"submission_ID": "1cbpprl", "submission_Title": "Best database to hold network data for long term", "submission_Score": 2, "submission_Author": "LobsterMost5947", "submission_selftext": " Hi All,   \n\nWe use ELK stack for internal network monitoring where we index  logs, metrics and alerts. This is the solution we are using for last 1  year and it is great with minor hiccups. Now we want to extend existing  solution to next level by analyzing the data before we index the same  for searching. As per my understanding we need to store the data and  perform analysis of the same before we index it in ELK.   \n\nWhat would be the ideal database to store live monitoring data which  contains logs in syslog format, metrics, state information of protocols  from 1k devices and perform live analysis of the same ?   ", "Create Date": "2024-04-24 04:45:39+00:00"}, {"submission_ID": "1cbkvjb", "submission_Title": "Databricks Asset Bundles now GA - thoughts? ", "submission_Score": 13, "submission_Author": "justanator101", "submission_selftext": "Databricks announced that assert bundles has become GA - https://www.databricks.com/blog/announcing-general-availability-databricks-asset-bundles. They also teased a future feature, ability to write DABS in Python. \n\nMy work is looking at switching to DAB from Terraform. Are you currently using it? Any gotchas or issues you\u2019ve had? ", "Create Date": "2024-04-24 00:37:18+00:00"}, {"submission_ID": "1cbkotm", "submission_Title": "Single vs man Data Warehouses", "submission_Score": 6, "submission_Author": "scan-horizon", "submission_selftext": "I work at a company with 200+ staff spread across 5 core departments. We have a presence in Azure and MS Entra.\n\nWe are currently in the midst of a debate around using a single DW for the entire company, or multiple DWs with each serving the specific needs of each department and teams within. The DWs would be used for staff to query data in their business area (so it\u2019s an OLAP dw).\n\nWe currently have a complex Azure DW (Azure data factory + Azure Databricks) which processes and serves travel and transport data to internal users, external users from other businesses, and also the data is available to the general public.\n\nA different department wants a DW to store their data which is highly sensitive / personal. None of this data relates to the data in the transport DW. The solution would be a data factory moving data between SQL databases, and interfaces with Power Apps/BI apps. Only select users can ever see the data stored here.\n\nOther departments now want DWs to process and store their data (for example, a place to keep all our workstreams, projects, and client info across the company).\n\nSo lots of different use cases, but all requiring some kind of DW to take data from various sources, transform it, and load it into databases/sink ready for consumption. I\u2019m suggesting each business case should have their own DW solution whereas my bosses are suggesting a single solution so we don\u2019t have loads of different DWs all over the place. Any thoughts on the best approach to take from a DE stance? Keep in mind we\u2019d want a solution with minimal billing/administrative overhead as our DE team is tiny. Thanks", "Create Date": "2024-04-24 00:28:27+00:00"}, {"submission_ID": "1cbhw1f", "submission_Title": "How is the performance of managers measured within Data Engineering", "submission_Score": 5, "submission_Author": "Mr-Bovine_Joni", "submission_selftext": "Hey all, current DE IC here - thinking vaguely about moving into manager roles\n\n**The questions is less \u201cwhat makes a good manager\u201d - but rather, how do directors gauge the performance of managers? **\n\nFrom the outside looking in it all seems much more subjective than being an individual contributor - just more meetings, people management, priority management \n\nIn general I think I could do it - I\u2019ve lead small teams in the past. But I worry about getting a manager role and not knowing what skills to grow\n\nI\u2019m sure all companies do it differently. Would love any thoughts! ", "Create Date": "2024-04-23 22:23:35+00:00"}, {"submission_ID": "1cbgwfr", "submission_Title": "Anyone ever import walmart ad data?", "submission_Score": 1, "submission_Author": "meyerovb", "submission_selftext": "I can get snapchat/facebook/google/tiktok ads, no problem (airbyte/hevo)... looks like walmart locks down their api to ad partners?", "Create Date": "2024-04-23 21:43:25+00:00"}, {"submission_ID": "1cbgswz", "submission_Title": "Design question about architecture for high availability datasets", "submission_Score": 2, "submission_Author": "nariver1", "submission_selftext": "Hey guys, hope everyone is doing fine! \n\nI have the following situation and I would like to read different opinions.\n\nSituation:\n\n* We have 3 data sources (all file based) with one table each source (for the sake of the context)\n* We read that data, we process it by joining data and doing some actions on it\n* We expose it on MySQL normalized enough to have various tables to join\n* This data is exposed through an API endpoint that basically runs the query joining the data\n\nClearly this is running some slowness and scalability issues so our next step is define how to improve performance without sacrificing too much update time of the data.\n\nWe have two approaches:\n\n1. Materialize results with certain cadence \n   * I'm thinking here an airflow dag running each 15'\n   * Data either pre processed or already modeled, will be moved to a different database\n2. Move towards event based actions\n   * Pretty sure standard here is to use kafka and ksql to join data or move data to a different place for processing\n\nMy question would be:\n\n* Question for point 1, would it be ok use airflow to run, let's say, dags each 5' to move data from MySQL 1 to MySQL 2? Already processed or not. Not sure if is an issue run DAGs with high frequence.\n* And more open question, is it out there any other technology that helps to process data fast and expose it for an endpoint that can be consumed with high workload? I think NoSQL database will be good for this scenario such as Mongo.\n\nThanks", "Create Date": "2024-04-23 21:39:39+00:00"}, {"submission_ID": "1cbeu50", "submission_Title": "A synchronous streaming model", "submission_Score": 7, "submission_Author": "woggle_bug", "submission_selftext": "", "Create Date": "2024-04-23 20:21:29+00:00"}, {"submission_ID": "1cbef8q", "submission_Title": "The Birth of SQL & the Relational Database - Asianometry", "submission_Score": 1, "submission_Author": "tomekanco", "submission_selftext": "", "Create Date": "2024-04-23 20:05:08+00:00"}, {"submission_ID": "1cbcfsv", "submission_Title": "CSV viewer/editor with formatting", "submission_Score": 2, "submission_Author": "sidewise8", "submission_selftext": "Does anyone know of a good CSV viewer that can save formatting? (potentially as a sidecar file to the CSV file) Like if I want to color the background of certain rows or adjust column widths. It would also be a plus if I could even hide or move around rows in the viewer without changing anything in the actual CSV file. I've used Excel and LibreOffice to edit the CSV files before, but I want to save my formatting.\n\nEDIT: I should add that the point of this is to keep the data in CSV format so it can be used with my data analysis pipeline (in Python), while being able to view it in a way I want also.", "Create Date": "2024-04-23 18:46:25+00:00"}, {"submission_ID": "1cbbj06", "submission_Title": "Which tools would you recommend for learning as \"industry standard\" to someone looking for a career change?", "submission_Score": 1, "submission_Author": "dataismysuperpower", "submission_selftext": "Hello. PM here with CS degree and 2 year DE experience before moving to PM work.\n\nI'm tired of my role and looking forward to come back to being a DE.\n\nI do know my way about Python and basic libraries.\nI also have experience with SQL and Power BI from my times as a PM.\n\nWhat other tools do you think are the \"industry standard\" at this point for DE roles?\n\nSo far I've seen in my last companies a little bit of people focusing on\n\nDatabricks\nPower BI\nTrino\nSQL Server\n\nWould you agree? Any other modern and widely accepted tools that would help me transit careers?\n\nMy main intention is to build some projects portfolio with real data (I've already scraped some real state sites, for example) to showcase interviewers since I don't think I'd be able to leverage my previous DE experience (it was seven years ago).\n\nThanks in advance!", "Create Date": "2024-04-23 18:10:18+00:00"}, {"submission_ID": "1cbbcdn", "submission_Title": "The Data Engineer's Guide to Building Data Products in Minutes, not Months", "submission_Score": 0, "submission_Author": "Dkreig", "submission_selftext": "In today's data-driven landscape, the demand for creating high-quality Data Products more quickly is greater than ever. In this hands-on webinar for data engineers and data product owners, you will learn how we use DataOps.live Create and DataOps.live Assist to build trusted Data Products literally in minutes.\n\nIn this webinar, you'll see a data owner and a data engineer:\n\n* Build and Develop a Data Product\n* Operationalize it as a data pipeline\n* Review and approve all changes before it goes live\n* And finally promote it to production\n* In less than 30 minutes!\n\nJoin us\u00a0**April 25th, 8am PDT | 11am EDT | 4pm GMT**.\n\n  \nRSVP here - [https://www.dataops.live/dataproductsinminutes](https://www.dataops.live/dataproductsinminutes)", "Create Date": "2024-04-23 18:03:07+00:00"}, {"submission_ID": "1cbamp4", "submission_Title": "Career Advice for Existing DE Moving Up to Senior DE and Beyond?", "submission_Score": 6, "submission_Author": "Oldwoodforest", "submission_selftext": "Tldr; as an existing data engineer, what should I be doing/learning to advance my skills (and career)?\n\nHave seen a lot of great advice and resources on here for people who are breaking into DE from a different career. Like many of those, years back I was working as a data analyst with a lot of overlapping skills and responsibilities to data engineering, and successfully made the jump a couple years ago. Since then, have had lots of exposure and projects using a lot of the usual DE suspects \u2013 ETL (s3->python/scala->redshift), job orchestration (via Airflow and more recently via Databricks), AWS, Databricks, etc. However, I have found myself in a rut where I am not really sure what I should be learning/doing to get to the next level.\n\nWhen I first started, I was by far the most junior DE on my team (all staff and principal engineers), but had a great DE manager who mentored me and provided assignments and projects to get me transitioned. Fast forward a year, and most of my team (and manager) had moved on to other companies and I lost that mentorship \u2013 but suddenly I was drinking from the firehose on a skeleton-crew team of just a few people, left largely to figure out things on my own. This did help me grow quite a bit as well, but it meant that all my learning from that point onwards was focused on whatever crisis or urgent project was on my plate. My company has other DE teams, but they are pretty silo\u2019d off to other branches of the business so that we only occasionally interact when there are company-wide infrastructure or tool changes. I am still on a skeleton-crew team where we large chunks of the year handling infrastructure or major tool changes as our primary projects keeping our supported parts of the business working, with roughly the other half of the year designing and creating new ETL\u2019s, pipelines, and other projects.\n\nI have tried to get some mentorship or direction within my company without much success. My management above me are not DE\u2019s, and the other few DE\u2019s I have contact with within my company/team have been pretty vague or uninterested. I have been working on some certifications (currently preparing to take the Databricks Certified Data Engineer Associate certification since we work a lot with Databricks), and have been perusing some of the DE resources linked to this reddit to shore up my foundational knowledge. Not specifically planning to stay or leave, but after being on such a lean team for so long, I feel like I would have better opportunities somewhere else, so I am happy to learn and develop new skills that would help my career growth, not just my current job (though that is a plus too).", "Create Date": "2024-04-23 17:34:23+00:00"}, {"submission_ID": "1cb95lt", "submission_Title": "Does transition from Devops(infra/platform) to data engineering make sense?", "submission_Score": 3, "submission_Author": "colderness", "submission_selftext": "Hi everyone,\n\nI got an offer but role is not specific. It's like a de job but they need a cloud engineer too. they use cloud, kubernetes, airflow etc. i told them i don't know anything about de. They said you can learn, i can learn of course but i'm not sure of this path, What do de guys think about someone from infra getting a both infra and de job? Any advice?\n\n&#x200B;", "Create Date": "2024-04-23 16:35:17+00:00"}, {"submission_ID": "1cb9365", "submission_Title": "Data Engineering Survey", "submission_Score": 1, "submission_Author": "dataengineeringdude", "submission_selftext": "", "Create Date": "2024-04-23 16:32:28+00:00"}, {"submission_ID": "1cb8yh8", "submission_Title": "What Signals Do you Look for to determine whether a Pipeline should be Streaming over Batch?", "submission_Score": 20, "submission_Author": "AMDataLake", "submission_selftext": "What signals to you that you should take a streaming approach over batch?", "Create Date": "2024-04-23 16:27:12+00:00"}, {"submission_ID": "1cb7mqe", "submission_Title": "Lakehouse doesn't seem to be advantageous for our Data Warehouse. Am I missing something(s)?", "submission_Score": 45, "submission_Author": "cdigioia", "submission_selftext": "We're a Microsoft shop that went from a SQL Server data warehouse (DW), to a Lakehouse DW in Synaspse Serverless, with our facts & dims in Delta tables.  It seems worse.  \n\nI'm thinking Azure SQL, *rather than Databricks*, would have been / would be better for our stiuation. \n\nThat said: \n\n  * I'm not a data engineer (Nor do we have one)\n  * I may be biased, given my only experience is with Synapse Serverless, and pretty sure Databricks is much better. \n  * I *am* sold on our datalake as an ingestion point, just not a *Lakehouse for our DW*\n\nSo here's a lakehouse.  Wow, all these advantages, except none seem to apply to us very much:\n\n  * Ability to fine tune and scale compute with variously sized Spark pools spinning up (then down) as needed.  That is legitimately *neat*. A static compute in SQL Server worked great for us though\n  * Opens up your Facts & Dims to easy acess with additional languages in Spark Notebooks (PySpark at least...perhaps someone uses Scala).  Nope, no-one has utilized that here. No-one is clamoring for it. \n  * Cheap storage.  True, but our data warehouse on SQL Server was like 70GB so...\n\nOn the flip side, read performance of Delta tables (in Synapse Serverless) is quite a bit worse than unoptimized Azure SQL / SQL Server, and development is a fair bit more onerous.  \n\nAm I missing something(s) on why a Lakehouse architecture would be better for our DW?", "Create Date": "2024-04-23 15:34:59+00:00"}]