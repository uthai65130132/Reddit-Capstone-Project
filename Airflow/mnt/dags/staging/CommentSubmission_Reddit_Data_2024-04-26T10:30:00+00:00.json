[{"comment_ID": "l1c450d", "comment_Body": "I think you are asking in the wrong sub - if your alternative is dask jobs and you are talking about high performance cpp and python. I would suggest r/HPC ?\n\n  \nspark was designed for massively parallel 'simple' processing on enormous datasets. rather than high performance clusters which I think is what you are after", "comment_Score": 1, "comment_Author": "seanv507", "comment_Link_id": "1cdg89d", "Create Date": "2024-04-26 11:28:01+00:00"}, {"comment_ID": "l1c3odn", "comment_Body": "exactly. if you didn't need it before you certainly don't need it now. It's certainly not a 'boring technology'", "comment_Score": 1, "comment_Author": "seanv507", "comment_Link_id": "1cdg89d", "Create Date": "2024-04-26 11:24:10+00:00"}, {"comment_ID": "l1c2je0", "comment_Body": "I have noticed that mentioning mage gets you down votes around here. I'm using mage and I think for my use case it's appropriate.  \n\nMage has some deficiencies but overall the experience has been good. \n\nMy 2 major concerns are \n\n1. It is slow but Mage has said they are prioritizing speed this year. \n\n2. Will it continue to be open source. It's VC funded and eventually they will want to monetize.", "comment_Score": 2, "comment_Author": "wannabe-DE", "comment_Link_id": "1cda190", "Create Date": "2024-04-26 11:14:16+00:00"}, {"comment_ID": "l1c2hvm", "comment_Body": "That's excellent! A great way to automate simple stuff then instead of paying AWS or running locally", "comment_Score": 1, "comment_Author": "Comfortable_Spread", "comment_Link_id": "1cd0tmv", "Create Date": "2024-04-26 11:13:54+00:00"}, {"comment_ID": "l1c2f9a", "comment_Body": "AI can't make that job for you. It is exactly the opposite of making consious effort. Connection between business process and data repressing it is outside of scope information given to AI engin, it has no connection to real physical world.", "comment_Score": 1, "comment_Author": "baubleglue", "comment_Link_id": "1ccdveg", "Create Date": "2024-04-26 11:13:14+00:00"}, {"comment_ID": "l1c1y8g", "comment_Body": "Well, It depends on your perspective and the scale of your data. Spark does its job well and indeed a powerful tool in the data batch/micro batch processing game. The main advantage is its open source. May be try joining your data sets using  high-performance CPP, Python and spark to know the difference!\n\nHowever, if your data requirements are more modest, Dask is certainly worth considering as well.", "comment_Score": 1, "comment_Author": "Rude-Veterinarian-45", "comment_Link_id": "1cdg89d", "Create Date": "2024-04-26 11:08:58+00:00"}, {"comment_ID": "l1c1t87", "comment_Body": "I understand high performance cpp.\n\nWTF is high performance python \ud83d\ude2c. Python is good enough for scripting and hobby projects.\n\nIf you\u2019re looking for true high performance and true object oriented language option for Spark, look at Scala.\n\nSorry to hurt the Python fan\u2019s feelings.\n\nComing back to Spark being boring, to have challenging tasks try work on performance optimization on shared on-Prem clusters(most of the early adopters of big data are still on prem).", "comment_Score": -1, "comment_Author": "RevolutionaryBid2619", "comment_Link_id": "1cdg89d", "Create Date": "2024-04-26 11:07:41+00:00"}, {"comment_ID": "l1c1fjb", "comment_Body": "You didn't need a chart to see the massive uptick in useless influencers. We're headed for the same fate as data science and data warehousing. That was the theme of my talk at Data Day Texas.", "comment_Score": 1, "comment_Author": "eljefe6a", "comment_Link_id": "1ccsf39", "Create Date": "2024-04-26 11:04:10+00:00"}, {"comment_ID": "l1c1bft", "comment_Body": "GitHub owns the computer here. On private repos you get X free minutes a month. On public repos you get unlimited amounts of minutes a month.", "comment_Score": 2, "comment_Author": "Luxi36", "comment_Link_id": "1cd0tmv", "Create Date": "2024-04-26 11:03:05+00:00"}, {"comment_ID": "l1c1707", "comment_Body": "Not the only, you'll find exceptions, but that's generally the flow.", "comment_Score": 1, "comment_Author": "Thin_Platform5774", "comment_Link_id": "1cdfiow", "Create Date": "2024-04-26 11:01:56+00:00"}, {"comment_ID": "l1c0zgz", "comment_Body": "I find this a really interesting take and a way of thinking i haven't tried before so I will bite.\nI am currently a data engineer atn a group level  dataplatform of an international company. Every day we ingest hundreds of tables for multiple sources.\n\nWe use an orchestrator to every night do a batch load. So every night a main pipeline is started which then gets some metadata about the tables to be loaded. For every table the right type of sub pipeline is triggered which ingests and processes the data.\n\nIf that's done the data is loaded into data models after which the refreshes of PowerBI reports based on those datasets is triggered.\n\nHow would you go about this without an orchestrator?", "comment_Score": 1, "comment_Author": "blindbox2", "comment_Link_id": "1cda190", "Create Date": "2024-04-26 10:59:59+00:00"}, {"comment_ID": "l1bzyc4", "comment_Body": "Spark is great if your on Prem or on Databricks. But I'm seeing lesser and lesser folk using it as snowflake/big query becomes more popular", "comment_Score": 2, "comment_Author": "Hackerjurassicpark", "comment_Link_id": "1cdg89d", "Create Date": "2024-04-26 10:50:10+00:00"}, {"comment_ID": "l1bzjdc", "comment_Body": "I don't understand what you mean, just like all statistical lists, everyone will discuss the list and give their own opinions, no one will say that the list itself is a fact, and the person who sent the list will not be wrong.", "comment_Score": 0, "comment_Author": "Gezi-lzq", "comment_Link_id": "1ccodiy", "Create Date": "2024-04-26 10:46:07+00:00"}, {"comment_ID": "l1byn5s", "comment_Body": "jsonl .", "comment_Score": 1, "comment_Author": "Stick-Spiritual", "comment_Link_id": "1ccsms9", "Create Date": "2024-04-26 10:37:18+00:00"}, {"comment_ID": "l1byauj", "comment_Body": "That will just make the jobs market more competitive lol.", "comment_Score": 1, "comment_Author": "icest0", "comment_Link_id": "1ccsf39", "Create Date": "2024-04-26 10:33:48+00:00"}, {"comment_ID": "l1bxw10", "comment_Body": "I disagree that you need 10 CTEs stacked on one another to do basic transformations in SQL. Coupling transformations at the same aggregation level together produces far fewer lines of SQL", "comment_Score": 1, "comment_Author": "Grovbolle", "comment_Link_id": "1cdha2w", "Create Date": "2024-04-26 10:29:34+00:00"}, {"comment_ID": "l1bxr9z", "comment_Body": "This looks solid. Curious to find out if you think Airbyte would be a good addition for moving data to Postgres?", "comment_Score": 2, "comment_Author": "chonbee", "comment_Link_id": "1ccs3vs", "Create Date": "2024-04-26 10:28:10+00:00"}, {"comment_ID": "l1bxq26", "comment_Body": "Hey there u/erik0422, thanks for mentioning that as a solution. We're looking to do something similar and was hoping you have some advice. We have all our data in databricks delta tables, and were looking to use Trino instead of Databricks' SQL Serveless Warehouse to save on costs. Trino has a Delta Lake connector which we were hoping to use without having to migrate the data (https://trino.io/docs/current/connector/delta-lake.html)\n\n  \nWe found Amazon EMR has support for Trino embedded (https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-presto.html) - is that something you used, and were able to connected to Delta Lake with? Thanks in advance for taking the time!", "comment_Score": 1, "comment_Author": "pragyajswl", "comment_Link_id": "1c42ckw", "Create Date": "2024-04-26 10:27:50+00:00"}, {"comment_ID": "l1bxpf8", "comment_Body": "Agree with this, but, I just use VPN tools/apps in windows as I do need to hop, given the Microsoft suite employed by my company (e.g., Teams). Might be the one caveat for you OP: use VPN tools in windows, but do your heavy lifting in WSL2. Working like a charm on my end.", "comment_Score": 1, "comment_Author": "dgrsmith", "comment_Link_id": "1cdc878", "Create Date": "2024-04-26 10:27:38+00:00"}, {"comment_ID": "l1bxkg6", "comment_Body": "Data Engineering is a flavour of Software Engineering. If you work on anything with backends/data etc you'll be well qualified for DE type roles/possibly be doing one under a different name. \n\n\n\n>Moreover, I'm curious about the salary prospects for freshers in the data engineering domain. Can I expect a competitive salary despite my lack of professional experience?\n\nNo more or less than any other technical role. Outside of a few outliers who win math prizes etc then you are normally less competitive as a Junior anyway. I wouldn't worry too much about it out the gate it'll grow very quickly over a couple years.", "comment_Score": 1, "comment_Author": "tdatas", "comment_Link_id": "1cdfiow", "Create Date": "2024-04-26 10:26:11+00:00"}, {"comment_ID": "l1bxdsq", "comment_Body": "I am doing this solo with some prepaid consultancy hours. Good thing the dwh is pretty simple but I do feel a bit stuck in place.", "comment_Score": 1, "comment_Author": "Demistr", "comment_Link_id": "1cdgbjw", "Create Date": "2024-04-26 10:24:15+00:00"}, {"comment_ID": "l1bx7sb", "comment_Body": "That\u2019s kinda sad. I\u2019ve been there.", "comment_Score": 1, "comment_Author": "nydasco", "comment_Link_id": "1cdgbjw", "Create Date": "2024-04-26 10:22:27+00:00"}, {"comment_ID": "l1bx535", "comment_Body": "Wrap everything in cte and select from them at the end.\n\n CTEs should be written with some logic behind it, every cte should do a specific thing if possible.\n\nFor example one cte for exchange rate calc, one for accounting cc split etc.\n\nDebugging long procs is pretty difficult by itself. I don't think you can set breakpoints like in Vs code.", "comment_Score": 1, "comment_Author": "Demistr", "comment_Link_id": "1cdha2w", "Create Date": "2024-04-26 10:21:41+00:00"}, {"comment_ID": "l1bwm3s", "comment_Body": "Just curious, where does the compute run here? Do we need to point to an EC2 machine?", "comment_Score": 1, "comment_Author": "Comfortable_Spread", "comment_Link_id": "1cd0tmv", "Create Date": "2024-04-26 10:16:03+00:00"}, {"comment_ID": "l1bwifn", "comment_Body": "There's noone at work to review my shit lol.", "comment_Score": 1, "comment_Author": "Demistr", "comment_Link_id": "1cdgbjw", "Create Date": "2024-04-26 10:14:57+00:00"}, {"comment_ID": "l1bwdr4", "comment_Body": "Both have a free tier and don't require a device running so as long as it's completely within the free tier, it's actually cheaper than running cron jobs on your own device.", "comment_Score": 1, "comment_Author": "HappEMason", "comment_Link_id": "1cd0tmv", "Create Date": "2024-04-26 10:13:32+00:00"}, {"comment_ID": "l1bw94g", "comment_Body": "I pretty much do this. Just install Linux versions of every software (vscode, docker, etc) directly in WSL2 and ignore windows completely, apart from chat/email. \n\nThe only issues are that if it\u2019s a work machine, networking can sometimes be a pain in the ass with VPNs, especially when running containers. There are some hacky ways around this (wsl vpn kit works pretty well https://github.com/sakai135/wsl-vpnkit), but sometimes you have to give up and use windows. All in all though, it\u2019s been working very well for me.", "comment_Score": 1, "comment_Author": "kyleekol", "comment_Link_id": "1cdc878", "Create Date": "2024-04-26 10:12:09+00:00"}, {"comment_ID": "l1bvyq2", "comment_Body": "Sorry to hijack your post but I'm currently thinking about purchasing a laptop for freelance work. I mainly work with Azure with the odd AWS/GCP stuff every now and then.\n\nI'm considering a Surface Laptop 6 or MacBook Air M3, both with 16GB RAM. I have a high-end desktop PC which I could remote desktop into from Mac if necessary.\n\nI used to have a Mac so I know how nice they are to work with. On the other hand, as I'm mainly working on Azure I should just stick to windows.\n\nWhat do you think? Should I go for Mac? Or should I just go windows all the way?", "comment_Score": 1, "comment_Author": "chonbee", "comment_Link_id": "1cdc878", "Create Date": "2024-04-26 10:09:00+00:00"}, {"comment_ID": "l1bvr42", "comment_Body": "I second u/Separate approach about taking a step back for a birds eye view. Working out what you eat", "comment_Score": 1, "comment_Author": "National-Two-8876", "comment_Link_id": "1ccy0s6", "Create Date": "2024-04-26 10:06:39+00:00"}, {"comment_ID": "l1bv4qy", "comment_Body": "Im saying dont use data hub write an api that matches your domain and a ui that displays your assets. If you use datahub and extend it to meet your needs you will commit just as much dev time.", "comment_Score": 1, "comment_Author": "I-mean-maybe", "comment_Link_id": "1cd8xbl", "Create Date": "2024-04-26 09:59:42+00:00"}, {"comment_ID": "l1buxg3", "comment_Body": "Firstly, thank you for  your insights. To give a bit more context: the entries will be times x-amount of users at a given moment. But I am exploring the opportunities to have a robust design for my application which when needed is easly scalable. I am familiar with relational databases and I thought there could be an issue and looked for NoSQL databases to store a lot of info. And was looking into neo4j and elastic search.", "comment_Score": 1, "comment_Author": "__bdude", "comment_Link_id": "1cd1ce6", "Create Date": "2024-04-26 09:57:25+00:00"}, {"comment_ID": "l1bux8v", "comment_Body": "I don't know why people feel that windows is all about gui.\n\nAs if mac and linux distros don't have gui at all.\n\nWindows has wsl, you also alternately have dev containers, dockers. You can use alacritty.", "comment_Score": 1, "comment_Author": "n3pst3r_007", "comment_Link_id": "1cdc878", "Create Date": "2024-04-26 09:57:22+00:00"}, {"comment_ID": "l1buqwr", "comment_Body": "So transitioning from other roles is the only way to get into data engineering?", "comment_Score": 1, "comment_Author": "ZenphyriX", "comment_Link_id": "1cdfiow", "Create Date": "2024-04-26 09:55:21+00:00"}, {"comment_ID": "l1buogu", "comment_Body": "I see, got it.. do you mind sharing the rough estimate of the workload.. just to get an idea.. :)", "comment_Score": 1, "comment_Author": "Tumbleweed-Afraid", "comment_Link_id": "1c8thmh", "Create Date": "2024-04-26 09:54:35+00:00"}, {"comment_ID": "l1buiza", "comment_Body": "Can we somehow move expectations to csv as well?", "comment_Score": 1, "comment_Author": "NikitaPoberezkin", "comment_Link_id": "198w13u", "Create Date": "2024-04-26 09:52:49+00:00"}, {"comment_ID": "l1btjed", "comment_Body": "Thank you for this.\n\nTo be honest it ended up being the latter. I spoke to my lead and he agreed that sometimes you just need to see something done a few times before you can start debugging it (he\u2019s from a cloud background too so he understands the transition pains). I\u2019m happy to do on-prem a bit, but we should be moving to cloud soon almost completely. I just don\u2019t want to pick up tools that will be redundant very soon.", "comment_Score": 1, "comment_Author": "JackalTheFulgid", "comment_Link_id": "1ccrag8", "Create Date": "2024-04-26 09:41:12+00:00"}, {"comment_ID": "l1bt90w", "comment_Body": "spark is a wonder of the world", "comment_Score": 5, "comment_Author": "sebastiandang", "comment_Link_id": "1cdg89d", "Create Date": "2024-04-26 09:37:49+00:00"}, {"comment_ID": "l1bsyju", "comment_Body": "No you're presenting opinions as fact. That's not doing your best, mistakes are fine but at least have a shred of self awareness", "comment_Score": 0, "comment_Author": "Ok_Raspberry5383", "comment_Link_id": "1ccodiy", "Create Date": "2024-04-26 09:34:21+00:00"}, {"comment_ID": "l1bstbw", "comment_Body": "Probably not. It is not an entry level role.", "comment_Score": 2, "comment_Author": "Thin_Platform5774", "comment_Link_id": "1cdfiow", "Create Date": "2024-04-26 09:32:34+00:00"}, {"comment_ID": "l1bsp06", "comment_Body": "can you share the code?", "comment_Score": 1, "comment_Author": "rental_car_abuse", "comment_Link_id": "1cbx8bb", "Create Date": "2024-04-26 09:31:05+00:00"}]